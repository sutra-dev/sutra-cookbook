{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joReEVmEQKK5"
      },
      "source": [
        "# ЁЯУЪ Multilingual Chat with PDF (Powered by SUTRA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMvVqesEZ9pY"
      },
      "source": [
        "<div style=\"display: flex; align-items: center; gap: 40px;\">\n",
        "\n",
        "<img src=\"https://play-lh.googleusercontent.com/_O9p4Z4yucA2NLmZBu9mTJCuBwXeT9NcbtrDN6I8gKlkIPRySV0adOmbyipjSj9Gew\" width=\"130\">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<div>\n",
        "  <h2>SUTRA by TWO Platforms</h2>\n",
        "  <p>SUTRA is a family of large multi-lingual language (LMLMs) models pioneered by Two Platforms. SUTRAтАЩs dual-transformer approach extends the power of both MoE and Dense AI language model architectures, delivering cost-efficient multilingual capabilities for over 50+ languages. It powers scalable AI applications for conversation, search, and advanced reasoning, ensuring high-performance across diverse languages, domains and applications.</p>\n",
        "\n",
        "</div>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/18BffQ6e0xrIpF97jRniLci2mAEvxHSl7?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGL1As_GaIt-"
      },
      "source": [
        "## Get Your API Keys\n",
        "\n",
        "Before you begin, make sure you have:\n",
        "\n",
        "1. A SUTRA API key (Get yours at [TWO AI's SUTRA API page](https://www.two.ai/sutra/api))\n",
        "2. Basic familiarity with Python and Jupyter notebooks\n",
        "\n",
        "This notebook is designed to run in Google Colab, so no local Python installation is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uQQHhIiN3CH"
      },
      "source": [
        "### 1. Install Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nPoxsbOLSoQ",
        "outputId": "d19adb48-79c6-4ed2-ac42-eadd182a0162"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m0.0/62.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m303.4/303.4 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain_openai langchain-community faiss-cpu requests pypdf python-docx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6HKziXMN6-2"
      },
      "source": [
        "### STEP 2 : Setup API Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcNUI6fWLZ0i"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set the API key from Colab secrets\n",
        "os.environ[\"SUTRA_API_KEY\"] = userdata.get(\"SUTRA_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJqLPi81OBVR"
      },
      "source": [
        "### STEP 3 :  Load the PDF Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpZ58RjuLfeC",
        "outputId": "fdeecbce-263a-4e16-f5c7-81e22bafc45b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 15 pages.\n"
          ]
        }
      ],
      "source": [
        "# ЁЯУН STEP 3: Load the PDF Document (replace 'example.pdf' as needed)\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"/content/NIPS-2017-attention-is-all-you-need-Paper.pdf\")\n",
        "documents = loader.load()\n",
        "print(f\"Loaded {len(documents)} pages.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdiY8_hpOPjp"
      },
      "source": [
        "### STEP 4 :  Split Documents into Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xRJTvRSLx6U",
        "outputId": "5cbd7c99-7758-4f84-f53c-86021b29f71a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split into 49 chunks.\n"
          ]
        }
      ],
      "source": [
        "# ЁЯУН STEP 4: Split Documents into Chunks\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=100\n",
        ")\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "print(f\"Split into {len(chunks)} chunks.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGZNvievOVz4"
      },
      "source": [
        "###STEP 5 :  Create Embeddings + FAISS Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShVnNGD1L1Nf"
      },
      "outputs": [],
      "source": [
        "# ЁЯУН STEP 5: Create Embeddings + FAISS Vector Store\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGDRWRNGOaMT"
      },
      "source": [
        "###STEP 6 :  Set Up Conversation Memory and RAG Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYFEFqY4MOYy",
        "outputId": "35eec509-c9d5-4140-a551-eb6805f8ba60"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-fc5334be7585>:6: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(\n"
          ]
        }
      ],
      "source": [
        "# ЁЯУН STEP 6: Set Up Conversation Memory and RAG Chain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    return_messages=True\n",
        ")\n",
        "\n",
        "# RAG model using Sutra\n",
        "rag_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm=ChatOpenAI(\n",
        "        api_key=os.getenv(\"SUTRA_API_KEY\"),\n",
        "        base_url=\"https://api.two.ai/v2\",\n",
        "        model=\"sutra-v2\",\n",
        "        temperature=0.5\n",
        "    ),\n",
        "    retriever=retriever,\n",
        "    memory=memory\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PXjWo34Og9W"
      },
      "source": [
        "###STEP 7 :  Ask Questions (Supports Multiple Languages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eo8C8HTMUzI"
      },
      "outputs": [],
      "source": [
        "# ЁЯУН STEP 7: Ask Questions (Supports Multiple Languages)\n",
        "def ask_question(question, language=\"English\"):\n",
        "    rag_response = rag_chain.invoke(question)\n",
        "    context = rag_response[\"answer\"]\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are a helpful assistant that answers questions about documents.\n",
        "    Use the following context to answer the question:\n",
        "\n",
        "    CONTEXT:\n",
        "    {context}\n",
        "\n",
        "    Please respond in {language}.\n",
        "\n",
        "    Question: {question}\n",
        "    \"\"\"\n",
        "\n",
        "    chat = ChatOpenAI(\n",
        "        api_key=os.getenv(\"SUTRA_API_KEY\"),\n",
        "        base_url=\"https://api.two.ai/v2\",\n",
        "        model=\"sutra-v2\",\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    from langchain.schema import HumanMessage\n",
        "    response = chat.invoke([HumanMessage(content=prompt)])\n",
        "    return response.content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dm4JfHOOo79"
      },
      "source": [
        "###STEP 8: Try It Out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASF6fpBUMakG",
        "outputId": "f26ff0e0-54e0-4dc5-b06c-6e330b9e29f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ЁЯФ╣ Response:\n",
            " Transformer рдПрдХ рдиреНрдпреВрд░рд▓ рдиреЗрдЯрд╡рд░реНрдХ рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рд╣реИ рдЬреЛ рдкреВрд░реА рддрд░рд╣ рд╕реЗ рдзреНрдпрд╛рди рддрдВрддреНрд░ (attention mechanisms) рдкрд░ рдирд┐рд░реНрднрд░ рдХрд░рддрд╛ рд╣реИ, рдЬрд┐рд╕рд╕реЗ рдкреБрдирд░рд╛рд╡реГрддреНрдд (recurrent) рдпрд╛ рд╕рдВрдХреБрдЪрди (convolutional) рдкрд░рддреЛрдВ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рд╕рдорд╛рдкреНрдд рд╣реЛ рдЬрд╛рддреА рд╣реИред рдЗрд╕реЗ 2017 рдореЗрдВ рд╡рд╛рд╕рд╡рд╛рдиреА рдФрд░ рдЕрдиреНрдп рджреНрд╡рд╛рд░рд╛ рд▓рд┐рдЦреА рдЧрдИ рдкрддреНрд░ \"Attention Is All You Need\" рдореЗрдВ рдкреЗрд╢ рдХрд┐рдпрд╛ рдЧрдпрд╛ рдерд╛ред \n",
            "\n",
            "Transformer рдореЙрдбрд▓ рдПрдХ рдПрдирдХреЛрдбрд░-рдбреАрдХреЛрдбрд░ рд╕рдВрд░рдЪрдирд╛ рдореЗрдВ рд╣реЛрддрд╛ рд╣реИ, рдЬрд╣рд╛рдБ:\n",
            "\n",
            "- **рдПрдирдХреЛрдбрд░** рдЗрдирдкреБрдЯ рдЕрдиреБрдХреНрд░рдо рдХреЛ рдкреНрд░реЛрд╕реЗрд╕ рдХрд░рддрд╛ рд╣реИ рдФрд░ рдирд┐рд░рдВрддрд░ рдкреНрд░рддрд┐рдирд┐рдзрд┐рддреНрд╡ (continuous representations) рдЙрддреНрдкрдиреНрди рдХрд░рддрд╛ рд╣реИред\n",
            "- **рдбреАрдХреЛрдбрд░** рдЗрди рдкреНрд░рддрд┐рдирд┐рдзрд┐рдпреЛрдВ рдХреЛ рд▓реЗрддрд╛ рд╣реИ рдФрд░ рдЖрдЙрдЯрдкреБрдЯ рдЕрдиреБрдХреНрд░рдо рдХреЛ рдПрдХ рд╕рдордп рдореЗрдВ рдПрдХ рддрддреНрд╡ рдХреЗ рд░реВрдк рдореЗрдВ рдЙрддреНрдкрдиреНрди рдХрд░рддрд╛ рд╣реИ, рдкрд╣рд▓реЗ рд╕реЗ рдЙрддреНрдкрдиреНрди рдкреНрд░рддреАрдХреЛрдВ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╣реБрдПред\n",
            "\n",
            "Transformer рдХреА рдкреНрд░рдореБрдЦ рд╡рд┐рд╢реЗрд╖рддрд╛рдПрдБ рд╣реИрдВ:\n",
            "\n",
            "1. **рд╕реЗрд▓реНрдл-рдЕрдЯреЗрдВрд╢рди рддрдВрддреНрд░**: рдпрд╣ рдореЙрдбрд▓ рдХреЛ рд╡рд╛рдХреНрдп рдореЗрдВ рд╡рд┐рднрд┐рдиреНрди рд╢рдмреНрджреЛрдВ рдХреЗ рдорд╣рддреНрд╡ рдХреЛ рдПрдХ рджреВрд╕рд░реЗ рдХреЗ рд╕рд╛рдкреЗрдХреНрд╖ рдорд╛рдкрдиреЗ рдХреА рдЕрдиреБрдорддрд┐ рджреЗрддрд╛ рд╣реИ, рдЪрд╛рд╣реЗ рд╡реЗ рдЕрдиреБрдХреНрд░рдо рдореЗрдВ рдХрд┐рддрдиреА рднреА рджреВрд░ рдХреНрдпреЛрдВ рди рд╣реЛрдВред рдпрд╣ рд╢рдмреНрджреЛрдВ рдХреЗ рдмреАрдЪ рд╕рдВрдмрдВрдзреЛрдВ рдФрд░ рдирд┐рд░реНрднрд░рддрд╛рдУрдВ рдХреЛ рдкрдХрдбрд╝рдиреЗ рдХреЗ рд▓рд┐рдП рдорд╣рддреНрд╡рдкреВрд░реНрдг рд╣реИред\n",
            "\n",
            "2. **рдорд▓реНрдЯреА-рд╣реЗрдбреЗрдб рдЕрдЯреЗрдВрд╢рди**: рдХрдИ рдзреНрдпрд╛рди рддрдВрддреНрд░ рд╕рдорд╛рдирд╛рдВрддрд░ рдореЗрдВ рдЪрд▓рддреЗ рд╣реИрдВ, рдЬрд┐рд╕рд╕реЗ рдореЙрдбрд▓ рдЗрдирдкреБрдЯ рдХреЗ рд╡рд┐рднрд┐рдиреНрди рднрд╛рдЧреЛрдВ рдкрд░ рдПрдХ рд╕рд╛рде рдзреНрдпрд╛рди рдХреЗрдВрджреНрд░рд┐рдд рдХрд░ рд╕рдХрддрд╛ рд╣реИред\n",
            "\n",
            "3. **рдкреИрд░реЗрд▓рд▓рд╛рдЗрдЬреЗрд╢рди**: рдкреБрдирд░рд╛рд╡реГрддреНрдд рдореЙрдбрд▓реЛрдВ рдХреЗ рд╡рд┐рдкрд░реАрдд, рдЬреЛ рдЕрдиреБрдХреНрд░рдореЛрдВ рдХреЛ рдХреНрд░рдорд┐рдХ рд░реВрдк рд╕реЗ рдкреНрд░реЛрд╕реЗрд╕ рдХрд░рддреЗ рд╣реИрдВ, Transformers рдкреВрд░реЗ рдЕрдиреБрдХреНрд░рдореЛрдВ рдХреЛ рдПрдХ рд╕рд╛рде рдкреНрд░реЛрд╕реЗрд╕ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ, рдЬрд┐рд╕рд╕реЗ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдХреА рдЧрддрд┐ рдФрд░ рджрдХреНрд╖рддрд╛ рдореЗрдВ рдорд╣рддреНрд╡рдкреВрд░реНрдг рд╕реБрдзрд╛рд░ рд╣реЛрддрд╛ рд╣реИред\n",
            "\n",
            "4. **рд░рд╛рдЬреНрдп-рдХреЗ-рд░рд╛рдЬреНрдп рдкреНрд░рджрд░реНрд╢рди**: Transformer рдиреЗ рд╡рд┐рднрд┐рдиреНрди рдкреНрд░рд╛рдХреГрддрд┐рдХ рднрд╛рд╖рд╛ рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг рдХрд╛рд░реНрдпреЛрдВ рдореЗрдВ рд░рд╛рдЬреНрдп-рдХреЗ-рд░рд╛рдЬреНрдп рдкрд░рд┐рдгрд╛рдо рдкреНрд░рд╛рдкреНрдд рдХрд┐рдП рд╣реИрдВ, рдЬреИрд╕реЗ рдорд╢реАрди рдЕрдиреБрд╡рд╛рдж, рдЬрд┐рд╕рд╕реЗ рдпрд╣ рдкреБрдирд░рд╛рд╡реГрддреНрдд рдпрд╛ рд╕рдВрдХреБрдЪрди рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдкрд░ рдЖрдзрд╛рд░рд┐рдд рдкрд┐рдЫрд▓реЗ рдореЙрдбрд▓реЛрдВ рдХреЛ рдкреАрдЫреЗ рдЫреЛрдбрд╝ рджреЗрддрд╛ рд╣реИред\n",
            "\n",
            "рдХреБрд▓ рдорд┐рд▓рд╛рдХрд░, Transformer рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдЖрдзреБрдирд┐рдХ рдЧрд╣рд░реА рд╕реАрдЦрдиреЗ рдХреЗ рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдореЗрдВ рдПрдХ рдореМрд▓рд┐рдХ рдЖрдзрд╛рд░ рдмрди рдЧрдпрд╛ рд╣реИред\n"
          ]
        }
      ],
      "source": [
        "# ЁЯУН STEP 8: Try It Out!\n",
        "response = ask_question(\"what is transformer\", language=\"Hindi\")\n",
        "print(\"ЁЯФ╣ Response:\\n\", response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kFNYjZeOujB"
      },
      "source": [
        "##Finally Integrated UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490,
          "referenced_widgets": [
            "f1ff83b70fdd49a4916cb7b296c0e78e",
            "936845a96593421797289fa20733a6a7",
            "28691eacbf0e4b24bb8a7996cd0faa51",
            "a9c8ed7564854afdbb1cb917bd31f9a1",
            "57a2dc693edc439a9cc21b407f8a8122",
            "778b4cc3bfb740d6adf544ff071aba17",
            "ee6b3b899e3d4e6f8def68470abc4583",
            "d84d384ccb5a46148f2ecd3a610c54a4",
            "d030517a5ec94d93a094acd8dd663e26",
            "717d1e582b15493c8b96f48e5b2e798a",
            "a3ae2f9e741444149a0d94d098341638",
            "628aff5227c8414aba2fef292f785a91",
            "abd9f2d613d34e24a385a79f25de8608",
            "d338366d8471451981d3891823f2f6d5",
            "1c312031cd37450884e7f59c028989af",
            "6b7d5493d192465ba201aa5e45cb5226",
            "ef4243380ef24f61b6294dd4a4ff2c53",
            "8250627b7bc3453ab8b88ac29e484ae2",
            "b3f275d0f8ef42f0978a0cffe5ccc40c",
            "623a3a1edde4499ba81ae9da3c69d39d",
            "532ab4b2b3904ac7988dbf074d834eeb",
            "0c8fab512c814a26b46c5df397706931",
            "7f4b259817524dd3a415cffcea794ee8",
            "2051a7efb9c34baea9e9fcca9e27399c",
            "77cb84bba13e45359772e5702ee6504a",
            "92f5f5e71bfb4fca9d5a762ac6f80a69",
            "02c6a8b7868b48a3984640492cb24d3b",
            "6a34d03adda94e2c9df6439aec967360",
            "b8c6a87ed173496a81b43ed1380132ee"
          ]
        },
        "id": "v7ENw2ZJM9iV",
        "outputId": "be9243e6-3193-4f4a-f9b9-0aea0245fffa"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1ff83b70fdd49a4916cb7b296c0e78e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value=\"<h3 style='font-family:Arial;'>ЁЯУЪ Multilingual Chat with PDF (Upload from Local)</h3тАж"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 1. Imports\n",
        "import os\n",
        "import requests\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.schema import HumanMessage\n",
        "from tempfile import NamedTemporaryFile\n",
        "\n",
        "# 2. Setup LLM (Sutra)\n",
        "def get_sutra_model():\n",
        "    return ChatOpenAI(\n",
        "        api_key=os.getenv(\"SUTRA_API_KEY\"),\n",
        "        base_url=\"https://api.two.ai/v2\",\n",
        "        model=\"sutra-v2\",\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "# 3. Load and index PDF\n",
        "def load_and_index_pdf(pdf_path):\n",
        "    loader = PyPDFLoader(pdf_path)\n",
        "    docs = loader.load()\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "    chunks = text_splitter.split_documents(docs)\n",
        "\n",
        "    embeddings = OpenAIEmbeddings(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "    vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "\n",
        "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "    chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm=get_sutra_model(),\n",
        "        retriever=vectorstore.as_retriever(),\n",
        "        memory=memory\n",
        "    )\n",
        "    return chain\n",
        "\n",
        "# 4. UI Components\n",
        "\n",
        "# PDF File Upload widget\n",
        "pdf_file_upload = widgets.FileUpload(\n",
        "    accept='.pdf',\n",
        "    multiple=False,\n",
        "    description='ЁЯУБ Upload PDF',\n",
        "    layout=widgets.Layout(width='300px')\n",
        ")\n",
        "\n",
        "load_pdf_button = widgets.Button(\n",
        "    description=\"ЁЯФД Load PDF\",\n",
        "    button_style='info',\n",
        "    layout=widgets.Layout(width='150px')\n",
        ")\n",
        "\n",
        "status_output = widgets.Output()\n",
        "\n",
        "# Language dropdown\n",
        "languages = [\n",
        "    \"English\", \"Hindi\", \"Gujarati\", \"Bengali\", \"Tamil\",\n",
        "    \"Telugu\", \"Kannada\", \"Malayalam\", \"Punjabi\", \"Marathi\",\n",
        "    \"Urdu\", \"Assamese\", \"Odia\", \"Sanskrit\", \"Korean\",\n",
        "    \"Japanese\", \"Arabic\", \"French\", \"German\", \"Spanish\",\n",
        "    \"Portuguese\", \"Russian\", \"Chinese\", \"Vietnamese\", \"Thai\",\n",
        "    \"Indonesian\", \"Turkish\", \"Polish\", \"Ukrainian\", \"Dutch\",\n",
        "    \"Italian\", \"Greek\", \"Hebrew\", \"Persian\", \"Swedish\",\n",
        "    \"Norwegian\", \"Danish\", \"Finnish\", \"Czech\", \"Hungarian\",\n",
        "    \"Romanian\", \"Bulgarian\", \"Croatian\", \"Serbian\", \"Slovak\",\n",
        "    \"Slovenian\", \"Estonian\", \"Latvian\", \"Lithuanian\", \"Malay\",\n",
        "    \"Tagalog\", \"Swahili\"\n",
        "]\n",
        "\n",
        "lang_dropdown = widgets.Dropdown(\n",
        "    options=languages,\n",
        "    value=\"English\",\n",
        "    description='ЁЯМР Language:',\n",
        "    layout=widgets.Layout(width='300px')\n",
        ")\n",
        "\n",
        "chat_output = widgets.HTML(\n",
        "    value=\"<div style='padding:10px; font-family:Arial; font-size:14px; height:300px; overflow-y:auto; border:1px solid #ccc; border-radius:5px;'>Chat history will appear here...</div>\"\n",
        ")\n",
        "\n",
        "user_input = widgets.Text(\n",
        "    placeholder='Type your message...',\n",
        "    layout=widgets.Layout(flex='4', width='auto')\n",
        ")\n",
        "\n",
        "send_button = widgets.Button(\n",
        "    description=\"ЁЯУд Send\",\n",
        "    button_style='primary',\n",
        "    layout=widgets.Layout(flex='1', width='auto')\n",
        ")\n",
        "\n",
        "messages = []\n",
        "conversation_chain = None\n",
        "\n",
        "# 5. Load PDF Logic\n",
        "def on_load_pdf(b):\n",
        "    global conversation_chain\n",
        "    uploaded_files = pdf_file_upload.value\n",
        "\n",
        "    with status_output:\n",
        "        clear_output()\n",
        "        if not uploaded_files:\n",
        "            print(\"тЭМ Please upload a PDF file first.\")\n",
        "            return\n",
        "        try:\n",
        "            print(\"тП│ Processing uploaded PDF...\")\n",
        "\n",
        "            # Save uploaded content to a temp file\n",
        "            uploaded_file = list(uploaded_files.values())[0]\n",
        "            with NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp:\n",
        "                tmp.write(uploaded_file['content'])\n",
        "                tmp_path = tmp.name\n",
        "\n",
        "            conversation_chain = load_and_index_pdf(tmp_path)\n",
        "            print(\"тЬЕ PDF loaded and indexed successfully!\")\n",
        "        except Exception as e:\n",
        "            print(\"тЭМ Error:\", e)\n",
        "\n",
        "load_pdf_button.on_click(on_load_pdf)\n",
        "\n",
        "# 6. Chat Interaction Logic\n",
        "def on_send_click(b):\n",
        "    global conversation_chain\n",
        "    if conversation_chain is None:\n",
        "        with status_output:\n",
        "            clear_output()\n",
        "            print(\"тЭМ Load a PDF first.\")\n",
        "        return\n",
        "\n",
        "    user_text = user_input.value.strip()\n",
        "    if not user_text:\n",
        "        return\n",
        "\n",
        "    lang = lang_dropdown.value\n",
        "    messages.append(f\"<b style='color:#13f22d;'>You:</b> {user_text}\")\n",
        "\n",
        "    context_response = conversation_chain.invoke(user_text)\n",
        "    rag_context = context_response['answer']\n",
        "\n",
        "    system_msg = f\"\"\"\n",
        "You are a helpful assistant answering based on a document.\n",
        "Use this context: {rag_context}\n",
        "Always reply in: {lang}\n",
        "Question: {user_text}\n",
        "\"\"\"\n",
        "\n",
        "    chat_model = get_sutra_model()\n",
        "    sutra_response = chat_model.invoke([HumanMessage(content=system_msg)])\n",
        "    assistant_reply = sutra_response.content.strip()\n",
        "\n",
        "    messages.append(f\"<b style='color:#007acc;'>Assistant ({lang}):</b> {assistant_reply}\")\n",
        "\n",
        "    chat_html = \"<br>\".join(messages)\n",
        "    chat_output.value = f\"<div style='padding:10px; font-family:Arial; font-size:14px; height:300px; overflow-y:auto; border:1px solid #ccc; border-radius:5px;'>{chat_html}</div>\"\n",
        "\n",
        "    user_input.value = \"\"\n",
        "\n",
        "send_button.on_click(on_send_click)\n",
        "\n",
        "# 7. Final Layout\n",
        "input_row = widgets.HBox([user_input, send_button])\n",
        "pdf_row = widgets.HBox([pdf_file_upload, load_pdf_button])\n",
        "\n",
        "ui = widgets.VBox([\n",
        "    widgets.HTML(\"<h3 style='font-family:Arial;'>ЁЯУЪ Multilingual Chat with PDF (Upload from Local)</h3>\"),\n",
        "    pdf_row,\n",
        "    lang_dropdown,\n",
        "    chat_output,\n",
        "    input_row,\n",
        "    status_output\n",
        "])\n",
        "\n",
        "# 8. Display the App\n",
        "display(ui)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
