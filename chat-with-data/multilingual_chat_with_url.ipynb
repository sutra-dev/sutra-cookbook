{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqgJRXMePylK"
   },
   "source": [
    "# üìö Multilingual Chat With URL (Powered by SUTRA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8MVHp2j6Asvm"
   },
   "source": [
    "<div style=\"display: flex; align-items: center; gap: 40px;\">\n",
    "\n",
    "<img src=\"https://play-lh.googleusercontent.com/_O9p4Z4yucA2NLmZBu9mTJCuBwXeT9NcbtrDN6I8gKlkIPRySV0adOmbyipjSj9Gew\" width=\"130\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div>\n",
    "  <h2>SUTRA by TWO Platforms</h2>\n",
    "  <p>SUTRA is a family of large multi-lingual language (LMLMs) models pioneered by Two Platforms. SUTRA‚Äôs dual-transformer approach extends the power of both MoE and Dense AI language model architectures, delivering cost-efficient multilingual capabilities for over 50+ languages. It powers scalable AI applications for conversation, search, and advanced reasoning, ensuring high-performance across diverse languages, domains and applications.</p>\n",
    "\n",
    "</div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1c-qJecFt7c0xcZMMEvF3PHW1e3M0AAFl?usp=sharing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGKd0qeyA1UA"
   },
   "source": [
    "## Get Your API Keys\n",
    "\n",
    "Before you begin, make sure you have:\n",
    "\n",
    "1. A SUTRA API key (Get yours at [TWO AI's SUTRA API page](https://www.two.ai/sutra/api))\n",
    "2. Basic familiarity with Python and Jupyter notebooks\n",
    "\n",
    "This notebook is designed to run in Google Colab, so no local Python installation is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPwW1Lw_7fFm"
   },
   "source": [
    "### 1. Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9F0TyWej7Z8L",
    "outputId": "9ecb6017-12b5-48c4-9f7d-cce35b7aa270"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/62.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m303.4/303.4 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain langchain_openai langchain-community faiss-cpu requests pypdf python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Ev0mGaUbsCz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "# Set the API key from Colab secrets\n",
    "os.environ[\"SUTRA_API_KEY\"] = userdata.get(\"SUTRA_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4r1JJZ1_U01"
   },
   "source": [
    "###Setup API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1II6I24s9JiU"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "# Set the API key from Colab secrets\n",
    "os.environ[\"SUTRA_API_KEY\"] = userdata.get(\"SUTRA_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glxZYmn67u0v"
   },
   "source": [
    "###  2. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovSWsqyn7sB1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.schema import HumanMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65EAkr_K7yvD"
   },
   "source": [
    "###  3. Function to Download PDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9Kl7_wG74SD"
   },
   "outputs": [],
   "source": [
    "def download_pdf(pdf_url, save_path=\"downloaded.pdf\"):\n",
    "    response = requests.get(pdf_url)\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6Qdb89n75Lk"
   },
   "source": [
    "### 4. Function to Load Chat Model (Sutra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GqD1w_mj78SB"
   },
   "outputs": [],
   "source": [
    "def get_chat_model():\n",
    "    return ChatOpenAI(\n",
    "        api_key=os.getenv(\"SUTRA_API_KEY\"),\n",
    "        base_url=\"https://api.two.ai/v2\",\n",
    "        model=\"sutra-v2\",\n",
    "        temperature=0.7\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mcwens7Z8wFG"
   },
   "source": [
    "###  5. Function to Process Documents into Conversation Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7-TUETqi8zRw"
   },
   "outputs": [],
   "source": [
    "def process_documents(file_paths, chunk_size=1000, chunk_overlap=100):\n",
    "    documents = []\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        if file_path.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "            documents.extend(loader.load())\n",
    "        elif file_path.endswith(\".docx\"):\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "            documents.extend(loader.load())\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "    embeddings = OpenAIEmbeddings(api_key=os.getenv(\"OPENAI_API_KEY\"))  # Use OpenAI embeddings\n",
    "    vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\",\n",
    "        return_messages=True\n",
    "    )\n",
    "\n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=get_chat_model(),\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        memory=memory\n",
    "    )\n",
    "\n",
    "    return conversation_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LaqCYiUx8279"
   },
   "source": [
    "### 6. Function to Query the Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4A6iBjOx87Lj"
   },
   "outputs": [],
   "source": [
    "def process_chat(conversation_chain, user_input, selected_language):\n",
    "    rag_response = conversation_chain.invoke(user_input)\n",
    "    context = rag_response[\"answer\"]\n",
    "\n",
    "    system_message = f\"\"\"\n",
    "    You are a helpful assistant that answers questions about documents.\n",
    "    Use the following context to answer the question.\n",
    "\n",
    "    CONTEXT:\n",
    "    {context}\n",
    "\n",
    "    Please respond in {selected_language}.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [HumanMessage(content=f\"{system_message}\\n\\nQuestion: {user_input}\")]\n",
    "    chat = get_chat_model()\n",
    "    response = chat.invoke(messages)\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYfBSko-891K"
   },
   "source": [
    "### 7. Example Usage Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iee7yfM19As5",
    "outputId": "8c205e8c-158e-4a70-be95-c80b14ae6d7f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-c8c1eabde0a9>:21: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡§ö‡§ø‡§ï‡§® ‡§î‡§∞ ‡§ó‡•à‡§≤‡§Ç‡§ó‡§æ‡§≤ ‡§ï‡•ã ‡§®‡§æ‡§∞‡§ø‡§Ø‡§≤ ‡§ï‡•á ‡§¶‡•Ç‡§ß ‡§Æ‡•á‡§Ç ‡§∏‡•Ç‡§™ (‡§ü‡•â‡§Æ ‡§ñ‡§æ ‡§ó‡§æ‡§à) ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡§ø‡§Æ‡•ç‡§®‡§≤‡§ø‡§ñ‡§ø‡§§ ‡§ö‡§∞‡§£‡•ã‡§Ç ‡§ï‡§æ ‡§™‡§æ‡§≤‡§® ‡§ï‡§∞‡•á‡§Ç:\n",
      "\n",
      "### ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä (‡§è‡§ï ‡§∏‡§∞‡•ç‡§µ‡§ø‡§Ç‡§ó)\n",
      "- 150 ‡§ó‡•ç‡§∞‡§æ‡§Æ ‡§ö‡§ø‡§ï‡§®, ‡§õ‡•ã‡§ü‡•á ‡§ü‡•Å‡§ï‡§°‡§º‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§ï‡§ü‡§æ ‡§π‡•Å‡§Ü\n",
      "- 50 ‡§ó‡•ç‡§∞‡§æ‡§Æ ‡§Ø‡•Å‡§µ‡§æ ‡§ó‡•à‡§≤‡§Ç‡§ó‡§æ‡§≤, ‡§ï‡§ü‡§æ ‡§π‡•Å‡§Ü\n",
      "- 100 ‡§ó‡•ç‡§∞‡§æ‡§Æ ‡§π‡§≤‡•ç‡§ï‡§æ ‡§ï‡•Å‡§ö‡§≤‡§æ ‡§π‡•Å‡§Ü ‡§≤‡•á‡§Æ‡§®‡§ó‡•ç‡§∞‡§æ‡§∏, ‡§ú‡•Å‡§≤‡§ø‡§è‡§® ‡§Æ‡•á‡§Ç ‡§ï‡§ü‡§æ ‡§π‡•Å‡§Ü\n",
      "- 100 ‡§ó‡•ç‡§∞‡§æ‡§Æ ‡§∏‡•ç‡§ü‡•ç‡§∞‡•â ‡§Æ‡§∂‡§∞‡•Ç‡§Æ\n",
      "- 250 ‡§ó‡•ç‡§∞‡§æ‡§Æ ‡§®‡§æ‡§∞‡§ø‡§Ø‡§≤ ‡§ï‡§æ ‡§¶‡•Ç‡§ß\n",
      "- 100 ‡§ó‡•ç‡§∞‡§æ‡§Æ ‡§ö‡§ø‡§ï‡§® ‡§∏‡•ç‡§ü‡•â‡§ï\n",
      "- 3 ‡§ö‡§Æ‡•ç‡§Æ‡§ö ‡§®‡•Ä‡§Ç‡§¨‡•Ç ‡§ï‡§æ ‡§∞‡§∏\n",
      "- 3 ‡§ö‡§Æ‡•ç‡§Æ‡§ö ‡§Æ‡§õ‡§≤‡•Ä ‡§ï‡•Ä ‡§∏‡•â‡§∏\n",
      "- 2 ‡§™‡§§‡•ç‡§§‡•á ‡§ï‡§æ‡§´‡§ø‡§∞ ‡§≤‡§æ‡§á‡§Æ, ‡§ï‡§ü‡•Ä ‡§π‡•Å‡§à\n",
      "- 1-2 ‡§¨‡§∞‡•ç‡§°‡•ç‡§∏ ‡§Ü‡§à ‡§ö‡§ø‡§≤‡•Ä, ‡§ï‡•Å‡§ö‡§≤‡•Ä ‡§π‡•Å‡§à\n",
      "- 3 ‡§™‡§§‡•ç‡§§‡•á ‡§ß‡§®‡§ø‡§Ø‡§æ\n",
      "\n",
      "### ‡§§‡•à‡§Ø‡§æ‡§∞‡•Ä ‡§ï‡§æ ‡§∏‡§Æ‡§Ø: 10 ‡§Æ‡§ø‡§®‡§ü\n",
      "### ‡§™‡§ï‡§æ‡§®‡•á ‡§ï‡§æ ‡§∏‡§Æ‡§Ø: 20 ‡§Æ‡§ø‡§®‡§ü\n",
      "### ‡§ï‡•Å‡§≤ ‡§∏‡§Æ‡§Ø: 30 ‡§Æ‡§ø‡§®‡§ü\n",
      "\n",
      "### ‡§µ‡§ø‡§ß‡§ø:\n",
      "1. ‡§è‡§ï ‡§¨‡§∞‡•ç‡§§‡§® ‡§Æ‡•á‡§Ç ‡§ö‡§ø‡§ï‡§® ‡§∏‡•ç‡§ü‡•â‡§ï ‡§î‡§∞ ‡§®‡§æ‡§∞‡§ø‡§Ø‡§≤ ‡§ï‡§æ ‡§¶‡•Ç‡§ß ‡§ß‡•Ä‡§Æ‡•Ä ‡§Ü‡§Ç‡§ö ‡§™‡§∞ ‡§â‡§¨‡§æ‡§≤‡•á‡§Ç‡•§\n",
      "2. ‡§¨‡§∞‡•ç‡§§‡§® ‡§Æ‡•á‡§Ç ‡§ï‡§ü‡•á ‡§π‡•Å‡§è ‡§ó‡•à‡§≤‡§Ç‡§ó‡§æ‡§≤, ‡§≤‡•á‡§Æ‡§®‡§ó‡•ç‡§∞‡§æ‡§∏, ‡§ö‡§ø‡§ï‡§® ‡§ï‡•á ‡§ü‡•Å‡§ï‡§°‡§º‡•á ‡§î‡§∞ ‡§Æ‡§∂‡§∞‡•Ç‡§Æ ‡§°‡§æ‡§≤‡•á‡§Ç‡•§ ‡§ú‡§¨ ‡§∏‡•Ç‡§™ ‡§â‡§¨‡§≤‡§®‡•á ‡§≤‡§ó‡•á, ‡§§‡•ã ‡§á‡§∏‡•á ‡§Æ‡§õ‡§≤‡•Ä ‡§ï‡•Ä ‡§∏‡•â‡§∏ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§∏‡•Ä‡§ú ‡§ï‡§∞‡•á‡§Ç‡•§\n",
      "3. ‡§ú‡§¨ ‡§ö‡§ø‡§ï‡§® ‡§™‡•Ç‡§∞‡•Ä ‡§§‡§∞‡§π ‡§∏‡•á ‡§™‡§ï ‡§ú‡§æ‡§è, ‡§§‡§¨ ‡§á‡§∏‡§Æ‡•á‡§Ç ‡§ï‡§ü‡•Ä ‡§π‡•Å‡§à ‡§ï‡§æ‡§´‡§ø‡§∞ ‡§≤‡§æ‡§á‡§Æ ‡§ï‡•Ä ‡§™‡§§‡•ç‡§§‡§ø‡§Ø‡§æ‡§Å ‡§î‡§∞ ‡§ï‡•Å‡§ö‡§≤‡•Ä ‡§π‡•Å‡§à ‡§¨‡§∞‡•ç‡§°‡•ç‡§∏ ‡§Ü‡§à ‡§ö‡§ø‡§≤‡•Ä ‡§°‡§æ‡§≤‡•á‡§Ç‡•§\n",
      "4. ‡§¨‡§∞‡•ç‡§§‡§® ‡§ï‡•ã ‡§Ü‡§Ç‡§ö ‡§∏‡•á ‡§π‡§ü‡§æ ‡§¶‡•á‡§Ç ‡§î‡§∞ ‡§®‡•Ä‡§Ç‡§¨‡•Ç ‡§ï‡§æ ‡§∞‡§∏ ‡§Æ‡§ø‡§≤‡§æ‡§è‡§Å‡•§\n",
      "5. ‡§™‡§∞‡•ã‡§∏‡§®‡•á ‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§∏‡•Ç‡§™ ‡§ï‡•ã ‡§ß‡§®‡§ø‡§Ø‡§æ ‡§ï‡•Ä ‡§™‡§§‡•ç‡§§‡§ø‡§Ø‡•ã‡§Ç ‡§∏‡•á ‡§∏‡§ú‡§æ‡§è‡§Å‡•§\n",
      "\n",
      "### ‡§ü‡§ø‡§™‡•ç‡§∏:\n",
      "- ‡§™‡§ï‡§æ‡§®‡•á ‡§ï‡•Ä ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§ï‡•á ‡§¶‡•å‡§∞‡§æ‡§® ‡§Ü‡§Ç‡§ö ‡§ï‡•ã ‡§ï‡§Æ ‡§∞‡§ñ‡•á‡§Ç ‡§§‡§æ‡§ï‡§ø ‡§®‡§æ‡§∞‡§ø‡§Ø‡§≤ ‡§ï‡•á ‡§¶‡•Ç‡§ß ‡§ï‡§æ ‡§§‡•á‡§≤ ‡§Ö‡§≤‡§ó ‡§® ‡§π‡•ã‡•§\n",
      "- ‡§Ø‡§¶‡§ø ‡§Ü‡§™ ‡§™‡§∞‡§ø‡§™‡§ï‡•ç‡§µ ‡§ó‡•à‡§≤‡§Ç‡§ó‡§æ‡§≤ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç, ‡§§‡•ã ‡§Æ‡§æ‡§§‡•ç‡§∞‡§æ ‡§ï‡§Æ ‡§ï‡§∞‡•á‡§Ç‡•§\n",
      "- ‡§¨‡§∞‡•ç‡§§‡§® ‡§ï‡•ã ‡§Ü‡§Ç‡§ö ‡§∏‡•á ‡§π‡§ü‡§æ‡§®‡•á ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§®‡•Ä‡§Ç‡§¨‡•Ç ‡§ï‡§æ ‡§∞‡§∏ ‡§°‡§æ‡§≤‡§®‡•á ‡§∏‡•á ‡§á‡§∏‡§ï‡•Ä ‡§∏‡•Å‡§ó‡§Ç‡§ß ‡§¨‡§¢‡§º‡§§‡•Ä ‡§π‡•à‡•§\n",
      "- ‡§Ö‡§ó‡§∞ ‡§Ü‡§™ ‡§π‡§≤‡•ç‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§¶ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç ‡§§‡•ã ‡§Æ‡§ø‡§∞‡•ç‡§ö ‡§ï‡•Ä ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ ‡§ï‡§Æ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§\n",
      "\n",
      "‡§á‡§∏ ‡§∏‡•Ç‡§™ ‡§ï‡§æ ‡§Ü‡§®‡§Ç‡§¶ ‡§≤‡•á‡§Ç!\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Download the PDF\n",
    "pdf_url = \"https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"\n",
    "downloaded_pdf_path = download_pdf(pdf_url)\n",
    "\n",
    "# STEP 2: Process documents\n",
    "conversation_chain = process_documents([downloaded_pdf_path])\n",
    "\n",
    "# STEP 3: Ask a question\n",
    "user_input = \"How do I make chicken and galangal in coconut milk soup\"\n",
    "selected_language = \"hindi\"\n",
    "\n",
    "# STEP 4: Get response\n",
    "answer = process_chat(conversation_chain, user_input, selected_language)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqciGnDF_u69"
   },
   "source": [
    "### Finally Integrated UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 491,
     "referenced_widgets": [
      "de4fc6d4c6a14f1f8b7b95311bbeee67",
      "6d1db6f89a0143ba8382c141d821e79b",
      "33c52a49957f49da8f7cf55049aeeb06",
      "76895a0a37a145ec8085aee13740f1cb",
      "2d9c07487b5a4183aeb8f0c169752a84",
      "72bd48d4823b498dacf84361ff5d4af0",
      "dd9ee3d9790644efa8e6a79050a3b243",
      "8739a7126a2c489b9717190a6f907c18",
      "aa07f87c0e6641cd970295f286d85d22",
      "a389f305ea124d979d8c3687a2e69700",
      "57a84a6d4ec5423c98820cc6489ab900",
      "2810d2a31d674adea3cbcb9f798fcb07",
      "fe3c1f6d8ba4425fb2d9f45232dff12b",
      "6c5552e1a08a4fe4a395ad7b97fabc0e",
      "ec3931bd69284e66a9b81bf7ec4c6f43",
      "107271f5c17540158ef8dfb7219c7f27",
      "0ab451f76bed4028b0b05d5f8bb9a7a8",
      "d7e26e8934624de5b8bb862433a0368b",
      "54a3372eb555472fa6320be76f77dd23",
      "8f33bda9440b4bddaadd6798738bfb2a",
      "9ebcafe1979643e3bdb7fbbd2725d09a",
      "72e41f45d4c34716a4103f1d1e8ad6fc",
      "61d0b39816714be2a7b61dcf5cf8fec9",
      "687adfb489a2452e9ab4990090704ab7",
      "27a8ae78d6f742acbe696138a609693f",
      "b6798cbfd9234e60b4d08ee7a0f6f25f",
      "1926bf1d5c6d4b58a9fbf88a05e8445d",
      "0f96b9e245f84a14918773587d919a9e",
      "f0eb5b4961424e208daab9441d179577"
     ]
    },
    "id": "0z5kTlxM-Zww",
    "outputId": "a1898b78-7e6c-4210-91af-065668737870"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4fc6d4c6a14f1f8b7b95311bbeee67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<h3 style='font-family:Arial;'>üìö Multilingual Chat with PDF (Powered by Sutra)</h3>‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Imports\n",
    "import os\n",
    "import requests\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.schema import HumanMessage\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "# 2. Setup LLM (Sutra)\n",
    "def get_sutra_model():\n",
    "    return ChatOpenAI(\n",
    "        api_key=os.getenv(\"SUTRA_API_KEY\"),\n",
    "        base_url=\"https://api.two.ai/v2\",\n",
    "        model=\"sutra-v2\",\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "# 3. Load and index PDF\n",
    "def load_and_index_pdf(pdf_path):\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    docs = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "    embeddings = OpenAIEmbeddings(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "    chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=get_sutra_model(),\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        memory=memory\n",
    "    )\n",
    "    return chain\n",
    "\n",
    "# 4. UI Components\n",
    "\n",
    "# PDF URL field\n",
    "pdf_url_input = widgets.Text(\n",
    "    placeholder='Enter PDF URL...',\n",
    "    description='üìÑ PDF URL:',\n",
    "    layout=widgets.Layout(width='100%')\n",
    ")\n",
    "\n",
    "load_pdf_button = widgets.Button(\n",
    "    description=\"üîÑ Load PDF\",\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='150px')\n",
    ")\n",
    "\n",
    "status_output = widgets.Output()\n",
    "\n",
    "# Language dropdown\n",
    "languages = [\n",
    "    \"English\", \"Hindi\", \"Gujarati\", \"Bengali\", \"Tamil\",\n",
    "    \"Telugu\", \"Kannada\", \"Malayalam\", \"Punjabi\", \"Marathi\",\n",
    "    \"Urdu\", \"Assamese\", \"Odia\", \"Sanskrit\", \"Korean\",\n",
    "    \"Japanese\", \"Arabic\", \"French\", \"German\", \"Spanish\",\n",
    "    \"Portuguese\", \"Russian\", \"Chinese\", \"Vietnamese\", \"Thai\",\n",
    "    \"Indonesian\", \"Turkish\", \"Polish\", \"Ukrainian\", \"Dutch\",\n",
    "    \"Italian\", \"Greek\", \"Hebrew\", \"Persian\", \"Swedish\",\n",
    "    \"Norwegian\", \"Danish\", \"Finnish\", \"Czech\", \"Hungarian\",\n",
    "    \"Romanian\", \"Bulgarian\", \"Croatian\", \"Serbian\", \"Slovak\",\n",
    "    \"Slovenian\", \"Estonian\", \"Latvian\", \"Lithuanian\", \"Malay\",\n",
    "    \"Tagalog\", \"Swahili\"\n",
    "]\n",
    "\n",
    "lang_dropdown = widgets.Dropdown(\n",
    "    options=languages,\n",
    "    value=\"English\",\n",
    "    description='üåê Language:',\n",
    "    layout=widgets.Layout(width='300px')\n",
    ")\n",
    "\n",
    "chat_output = widgets.HTML(\n",
    "    value=\"<div style='padding:10px; font-family:Arial; font-size:14px; height:300px; overflow-y:auto; border:1px solid #ccc; border-radius:5px;'>Chat history will appear here...</div>\"\n",
    ")\n",
    "\n",
    "user_input = widgets.Text(\n",
    "    placeholder='Type your message...',\n",
    "    layout=widgets.Layout(flex='4', width='auto')\n",
    ")\n",
    "\n",
    "send_button = widgets.Button(\n",
    "    description=\"üì§ Send\",\n",
    "    button_style='primary',\n",
    "    layout=widgets.Layout(flex='1', width='auto')\n",
    ")\n",
    "\n",
    "messages = []\n",
    "conversation_chain = None\n",
    "\n",
    "# 5. Load PDF Logic\n",
    "def download_pdf(url):\n",
    "    response = requests.get(url)\n",
    "    tmp_file = NamedTemporaryFile(delete=False, suffix=\".pdf\")\n",
    "    with open(tmp_file.name, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    return tmp_file.name\n",
    "\n",
    "def on_load_pdf(b):\n",
    "    global conversation_chain\n",
    "    pdf_url = pdf_url_input.value.strip()\n",
    "    with status_output:\n",
    "        clear_output()\n",
    "        if not pdf_url:\n",
    "            print(\"‚ùå Please enter a valid PDF URL.\")\n",
    "            return\n",
    "        print(\"‚è≥ Downloading and processing PDF...\")\n",
    "        try:\n",
    "            pdf_path = download_pdf(pdf_url)\n",
    "            conversation_chain = load_and_index_pdf(pdf_path)\n",
    "            print(\"‚úÖ PDF loaded and indexed successfully!\")\n",
    "        except Exception as e:\n",
    "            print(\"‚ùå Error:\", e)\n",
    "\n",
    "load_pdf_button.on_click(on_load_pdf)\n",
    "\n",
    "# 6. Chat Interaction Logic\n",
    "def on_send_click(b):\n",
    "    global conversation_chain\n",
    "    if conversation_chain is None:\n",
    "        with status_output:\n",
    "            clear_output()\n",
    "            print(\"‚ùå Load a PDF first.\")\n",
    "        return\n",
    "\n",
    "    user_text = user_input.value.strip()\n",
    "    if not user_text:\n",
    "        return\n",
    "\n",
    "    lang = lang_dropdown.value\n",
    "    messages.append(f\"<b style='color:#13f22d;'>You:</b> {user_text}\")\n",
    "\n",
    "    context_response = conversation_chain.invoke(user_text)\n",
    "    rag_context = context_response['answer']\n",
    "\n",
    "    system_msg = f\"\"\"\n",
    "You are a helpful assistant answering based on a document.\n",
    "Use this context: {rag_context}\n",
    "Always reply in: {lang}\n",
    "Question: {user_text}\n",
    "\"\"\"\n",
    "\n",
    "    chat_model = get_sutra_model()\n",
    "    sutra_response = chat_model.invoke([HumanMessage(content=system_msg)])\n",
    "    assistant_reply = sutra_response.content.strip()\n",
    "\n",
    "    messages.append(f\"<b style='color:#007acc;'>Assistant ({lang}):</b> {assistant_reply}\")\n",
    "\n",
    "    chat_html = \"<br>\".join(messages)\n",
    "    chat_output.value = f\"<div style='padding:10px; font-family:Arial; font-size:14px; height:300px; overflow-y:auto; border:1px solid #ccc; border-radius:5px;'>{chat_html}</div>\"\n",
    "\n",
    "    user_input.value = \"\"\n",
    "\n",
    "send_button.on_click(on_send_click)\n",
    "\n",
    "# 7. Final Layout\n",
    "input_row = widgets.HBox([user_input, send_button])\n",
    "pdf_row = widgets.HBox([pdf_url_input, load_pdf_button])\n",
    "\n",
    "ui = widgets.VBox([\n",
    "    widgets.HTML(\"<h3 style='font-family:Arial;'>üìö Multilingual Chat with PDF (Powered by Sutra)</h3>\"),\n",
    "    pdf_row,\n",
    "    lang_dropdown,\n",
    "    chat_output,\n",
    "    input_row,\n",
    "    status_output\n",
    "])\n",
    "\n",
    "# 8. Display the App\n",
    "display(ui)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
