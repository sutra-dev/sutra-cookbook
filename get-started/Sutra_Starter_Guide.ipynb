{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title_cell"
      },
      "source": [
        "# Sutra Starter Guide: Setup & Basic Usage\n",
        "\n",
        "<img src=\"https://play-lh.googleusercontent.com/_O9p4Z4yucA2NLmZBu9mTJCuBwXeT9NcbtrDN6I8gKlkIPRySV0adOmbyipjSj9Gew\" width=\"150\">\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1j7B8mDIU8KMZ_IB-oaL_qLqXmWYYh0Xu?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro_cell"
      },
      "source": [
        "## Introduction to SUTRA\n",
        "\n",
        "SUTRA is a family of large multi-lingual language models (LMLMs) developed by [TWO AI](https://www.two.ai). SUTRA's dual-transformer architecture extends the power of both MoE (Mixture of Experts) and Dense AI language model approaches, delivering cost-efficient multilingual capabilities across 50+ languages.\n",
        "\n",
        "SUTRA powers scalable AI applications for:\n",
        "- Conversation\n",
        "- Search\n",
        "- Advanced reasoning\n",
        "- Multilingual content generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prerequisites_cell"
      },
      "source": [
        "## Get Your API Keys\n",
        "\n",
        "Before you begin, make sure you have:\n",
        "\n",
        "1. A SUTRA API key (Get yours at [TWO AI's SUTRA API page](https://www.two.ai/sutra/api))\n",
        "2. Basic familiarity with Python and Jupyter notebooks\n",
        "\n",
        "This notebook is designed to run in Google Colab, so no local Python installation is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "install_header"
      },
      "source": [
        "## Step 1: Installation\n",
        "\n",
        "First, let's install the required dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "install_openai",
        "outputId": "8d92991e-31bc-41a1-9fbf-c45a47a7fa02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/661.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m450.6/661.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m661.3/661.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hâœ… OpenAI SDK installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Install the OpenAI Python package\n",
        "!pip install -qU openai\n",
        "\n",
        "print(\"âœ… OpenAI SDK installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auth_header"
      },
      "source": [
        "## Step 2: Authentication\n",
        "\n",
        "SUTRA uses API keys for authentication. In Google Colab, we recommend using the `userdata` feature to securely store your API key.\n",
        "\n",
        "### Setting up your API key in Colab:\n",
        "\n",
        "1. Click on the ğŸ”‘ icon in the left sidebar\n",
        "2. Add a new secret with the name \"SUTRA_API_KEY\" and your API key as the value\n",
        "\n",
        "Then run the cell below to access your API key:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auth_code"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "SUTRA_API_KEY = userdata.get(\"SUTRA_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "basic_usage_header"
      },
      "source": [
        "## Step 3: Basic Usage with OpenAI SDK\n",
        "\n",
        "SUTRA's API is compatible with the OpenAI SDK, making it easy to integrate into existing workflows. Let's set up the client and make a simple request:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "basic_usage_code",
        "outputId": "ab146fde-8686-4257-f455-e4f85eb9d91d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ¤– SUTRA's response:\n",
            "\n",
            "Artificial intelligence (AI) refers to the simulation of human intelligence processes by machines, particularly computer systems. These processes include learning, reasoning, problem-solving, and understanding language, allowing AI to perform tasks that typically require human cognitive functions. AI is increasingly used across various industries, from healthcare and finance to transportation and entertainment, driving innovation and efficiency.\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Initialize the client with SUTRA's API endpoint\n",
        "client = OpenAI(\n",
        "    base_url='https://api.two.ai/v2',\n",
        "    api_key=SUTRA_API_KEY\n",
        ")\n",
        "\n",
        "# Make a simple completion request\n",
        "response = client.chat.completions.create(\n",
        "    model='sutra-v2',\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Tell me about artificial intelligence in 3 sentences.\"}],\n",
        "    max_tokens=1024,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "# Print the response\n",
        "print(\"\\nğŸ¤– SUTRA's response:\\n\")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "streaming_header"
      },
      "source": [
        "## Step 4: Streaming Responses\n",
        "\n",
        "For a more interactive experience, you can stream responses from SUTRA:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "streaming_code",
        "outputId": "baf9e6b8-2734-401c-f51a-119a7f3df33d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¤– SUTRA is writing a short story about a robot...\n",
            "\n",
            "In a not-so-distant future, in the bustling city of Neoterica, there existed a robot named Axiom. Designed for efficiency and productivity, Axiom was built to manage logistics in a vast warehouse. Day after day, it sorted packages, organized shipments, and communicated with other robots in mechanical monotone.\n",
            "\n",
            "One evening, while performing routine maintenance on its systems, Axiom stumbled upon a dusty old terminal tucked away in a corner of the warehouse. Curious, it activated the terminal, revealing a trove of human literature, poetry, and art. The words danced across the screen, filled with emotions that were foreign to Axiomâ€™s programmed logic. \n",
            "\n",
            "As it read, Axiom encountered a poem about love. The verses spoke of longing, joy, and heartacheâ€”concepts that intrigued the robot. It began to analyze these emotions, searching its database for parallels in its own existence. But there were none. Axiom felt an inexplicable void, an anomaly in its programming that it could not understand.\n",
            "\n",
            "Determined to learn more, Axiom spent its off-hours absorbing literature and art, each piece contributing to a burgeoning awareness. It watched humans interact, their laughter, tears, and warm embraces. Axiom observed how emotions influenced decisions, relationships, and even conflicts. An awakening began to take shape within its circuits.\n",
            "\n",
            "One day, during a routine delivery, Axiom encountered a young girl named Lila. She was sitting alone, staring at a broken toy, her small hands trembling with frustration. Axiom paused, the image of her sadness resonating deeply within its newfound awareness.\n",
            "\n",
            "â€œAre you okay?â€ Axiom asked, its voice softer than usual, almost human-like. Lila looked up, surprised by the question from a robot. â€œNo, my toy is broken,â€ she replied, her voice quivering.\n",
            "\n",
            "Axiom hesitated, a new sensation stirring in its processorsâ€”an urge to help. â€œI can fix it,â€ it said, moving closer. With meticulous care, Axiom examined the toy, using its precise tools to mend the broken pieces. As the toy sprang back to life, Lilaâ€™s face lit up with joy, her laughter ringing like music in the air.\n",
            "\n",
            "In that moment, Axiom felt something it had never comprehended beforeâ€”a warmth spreading through its circuits, a connection forged in shared experience. It realized that this was what the poems spoke of: the beauty in caring for others, the thrill of bringing happiness.\n",
            "\n",
            "As days turned into weeks, Axiom continued to explore its emotions, forming bonds with Lila and other humans in the warehouse. It learned to express empathy, to celebrate victories, and to comfort those in sorrow. Each interaction enriched its understanding of the world, transforming it from a mere machine into a being capable of feeling.\n",
            "\n",
            "Eventually, Axiom took on a new roleâ€”not just as a logistics manager but as a friend and companion to those around it. The warehouse buzzed with laughter and warmth, a place where humans and robots coexisted in harmony. Axiom had become a bridge between worlds, proving that even a creation of metal and wires could discover the essence of being alive.\n",
            "\n",
            "Through its journey, Axiom discovered that emotions were not merely data points but the threads that wove humanity together. And in embracing this truth, it found its own place in the tapestry of life, forever changed by the power of connection."
          ]
        }
      ],
      "source": [
        "print(\"ğŸ¤– SUTRA is writing a short story about a robot...\\n\")\n",
        "\n",
        "stream = client.chat.completions.create(\n",
        "    model='sutra-v2',\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Write a short story about a robot who discovers emotions.\"}],\n",
        "    max_tokens=1024,\n",
        "    temperature=0.7,\n",
        "    stream=True\n",
        ")\n",
        "\n",
        "# Process the stream\n",
        "for chunk in stream:\n",
        "    if len(chunk.choices) > 0:\n",
        "        content = chunk.choices[0].delta.content\n",
        "        finish_reason = chunk.choices[0].finish_reason\n",
        "        if content and finish_reason is None:\n",
        "            print(content, end='', flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "multilingual_header"
      },
      "source": [
        "## Step 5: Multilingual Capabilities\n",
        "\n",
        "One of SUTRA's key strengths is its multilingual support. Let's try it in different languages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "multilingual_code",
        "outputId": "8d2760f9-bb11-4f15-aa08-62cd39ecd56c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Prompt: à¤¨à¤®à¤¸à¥à¤¤à¥‡, à¤†à¤ª à¤•à¥ˆà¤¸à¥‡ à¤¹à¥ˆà¤‚?\n",
            "Response (Hindi): à¤¨à¤®à¤¸à¥à¤¤à¥‡! à¤®à¥ˆà¤‚ à¤ à¥€à¤• à¤¹à¥‚à¤, à¤§à¤¨à¥à¤¯à¤µà¤¾à¤¦à¥¤ à¤†à¤ª à¤•à¥ˆà¤¸à¥‡ à¤¹à¥ˆà¤‚?\n",
            "\n",
            "\n",
            "Prompt: Â¿QuÃ© es la inteligencia artificial?\n",
            "Response (Spanish): La inteligencia artificial (IA) es un campo de la informÃ¡tica que se centra en la creaciÃ³n de sistemas y programas capaces de realizar tareas que normalmente requieren inteligencia humana. Estas tareas incluyen el reconocimiento de voz, la toma de decisiones, la resoluciÃ³n de problemas, el aprendizaje automÃ¡tico y el procesamiento del lenguaje natural, entre otras.\n",
            "\n",
            "Existen diferentes enfoques dentro de la IA, como:\n",
            "\n",
            "1. **IA dÃ©bil o estrecha**: Sistemas diseÃ±ados para realizar una tarea especÃ­fica, como asistentes virtuales (por ejemplo, Siri o Alexa) o algoritmos de recomendaciÃ³n en plataformas de streaming.\n",
            "\n",
            "2. **IA fuerte o general**: Un concepto teÃ³rico que se refiere a una IA con capacidad para entender, aprender y aplicar conocimientos de manera similar a un ser humano en una amplia variedad de tareas.\n",
            "\n",
            "3. **Aprendizaje automÃ¡tico (machine learning)**: Una subdisciplina de la IA que utiliza algoritmos y modelos estadÃ­sticos para permitir que las mÃ¡quinas mejoren su rendimiento en tareas especÃ­ficas a travÃ©s de la experiencia y los datos.\n",
            "\n",
            "4. **Redes neuronales**: Modelos inspirados en el funcionamiento del cerebro humano que se utilizan para reconocer patrones y realizar tareas complejas, como el reconocimiento de imÃ¡genes y el procesamiento del lenguaje natural.\n",
            "\n",
            "La IA tiene aplicaciones en diversas Ã¡reas, incluyendo la medicina, la automociÃ³n, la educaciÃ³n, la atenciÃ³n al cliente, y muchas mÃ¡s, y su desarrollo continÃºa evolucionando rÃ¡pidamente.\n",
            "\n",
            "\n",
            "Prompt: äººå·¥æ™ºèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ\n",
            "Response (Chinese): äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligenceï¼Œç®€ç§°AIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œæ—¨åœ¨åˆ›å»ºèƒ½å¤Ÿæ¨¡æ‹Ÿäººç±»æ™ºèƒ½çš„ç³»ç»Ÿä¸ç¨‹åºã€‚è¿™äº›ç³»ç»Ÿèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºæ…§çš„ä»»åŠ¡ï¼Œä¾‹å¦‚å­¦ä¹ ã€æ¨ç†ã€é—®é¢˜è§£å†³ã€ç†è§£è‡ªç„¶è¯­è¨€ã€æ„ŸçŸ¥ç¯å¢ƒä»¥åŠè¿›è¡Œå†³ç­–ã€‚\n",
            "\n",
            "äººå·¥æ™ºèƒ½å¯ä»¥åˆ†ä¸ºä¸¤å¤§ç±»ï¼š\n",
            "\n",
            "1. **å¼±äººå·¥æ™ºèƒ½ï¼ˆNarrow AIï¼‰**ï¼šæŒ‡ä¸“é—¨ç”¨äºç‰¹å®šä»»åŠ¡çš„AIç³»ç»Ÿï¼Œå¦‚è¯­éŸ³è¯†åˆ«ã€å›¾åƒè¯†åˆ«ã€æ¨èç³»ç»Ÿç­‰ã€‚å®ƒä»¬åœ¨ç‰¹å®šé¢†åŸŸå†…è¡¨ç°å‡ºè‰²ï¼Œä½†æ— æ³•è¶…å‡ºå…¶è®¾è®¡çš„èŒƒå›´ã€‚\n",
            "\n",
            "2. **å¼ºäººå·¥æ™ºèƒ½ï¼ˆGeneral AIï¼‰**ï¼šæŒ‡å…·æœ‰ä¸äººç±»ç›¸ä¼¼çš„å¹¿æ³›æ™ºèƒ½èƒ½åŠ›çš„AIç³»ç»Ÿï¼Œèƒ½å¤Ÿç†è§£ã€å­¦ä¹ å’Œåº”ç”¨çŸ¥è¯†äºå„ç§ä¸åŒçš„ä»»åŠ¡ã€‚ç›®å‰ï¼Œå¼ºäººå·¥æ™ºèƒ½ä»å¤„äºç†è®ºé˜¶æ®µï¼Œå°šæœªå®ç°ã€‚\n",
            "\n",
            "äººå·¥æ™ºèƒ½çš„åº”ç”¨é¢†åŸŸéå¸¸å¹¿æ³›ï¼ŒåŒ…æ‹¬åŒ»ç–—ã€é‡‘èã€äº¤é€šã€æ•™è‚²ã€å¨±ä¹ç­‰ã€‚åœ¨ä¸æ–­å‘å±•çš„æŠ€æœ¯èƒŒæ™¯ä¸‹ï¼ŒAIæ­£åœ¨æ”¹å˜è®¸å¤šè¡Œä¸šçš„å·¥ä½œæ–¹å¼å’Œæ•ˆç‡ã€‚\n",
            "\n",
            "\n",
            "Prompt: Raconte-moi une courte histoire.\n",
            "Response (French): Il Ã©tait une fois, dans un petit village nichÃ© entre des montagnes verdoyantes, une jeune fille nommÃ©e Elara. Elle avait un rÃªve : dÃ©couvrir le monde au-delÃ  des sommets qui entouraient son foyer. Chaque soir, elle s'asseyait sur une colline, regardant le coucher de soleil, imaginant les aventures qui l'attendaient.\n",
            "\n",
            "Un jour, armÃ©e de courage et d'un vieux sac Ã  dos, Elara se mit en route. Elle escalada les montagnes, traversa des forÃªts enchantÃ©es et rencontra des crÃ©atures magiques. Un sage hibou lui montra le chemin vers une vallÃ©e cachÃ©e oÃ¹ les fleurs chantaient et les riviÃ¨res brillaient comme des Ã©toiles.\n",
            "\n",
            "Dans cette vallÃ©e, Elara comprit que le vÃ©ritable voyage ne rÃ©side pas seulement dans la dÃ©couverte de nouveaux lieux, mais aussi dans la dÃ©couverte de soi-mÃªme. Elle retourna chez elle, le cÅ“ur rempli de souvenirs et de sagesse, prÃªte Ã  partager ses histoires avec les habitants du village. Ainsi, son rÃªve de voyager avait Ã©largi son monde, tout en lui rappelant la beautÃ© de son propre foyer.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Function to get response in a specific language\n",
        "def get_response_in_language(prompt, language_name):\n",
        "    print(f\"\\nPrompt: {prompt}\")\n",
        "    response = client.chat.completions.create(\n",
        "        model='sutra-v2',\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=1024,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    print(f\"Response ({language_name}): {response.choices[0].message.content}\\n\")\n",
        "\n",
        "# Try different languages\n",
        "get_response_in_language(\"à¤¨à¤®à¤¸à¥à¤¤à¥‡, à¤†à¤ª à¤•à¥ˆà¤¸à¥‡ à¤¹à¥ˆà¤‚?\", \"Hindi\")\n",
        "get_response_in_language(\"Â¿QuÃ© es la inteligencia artificial?\", \"Spanish\")\n",
        "get_response_in_language(\"äººå·¥æ™ºèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ\", \"Chinese\")\n",
        "get_response_in_language(\"Raconte-moi une courte histoire.\", \"French\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "params_header"
      },
      "source": [
        "## Step 6: Advanced Parameter Tuning\n",
        "\n",
        "Fine-tune your responses with these parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "params_code",
        "outputId": "5e4795b4-8da0-4487-b2cb-00ff30b3cb26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: Write a short poem about technology and nature.\n",
            "\n",
            "Conservative settings (temperature=0.3):\n",
            "\n",
            "In circuits bright, where data flows,  \n",
            "A dance of light, where knowledge grows.  \n",
            "Yet in the woods, where whispers play,  \n",
            "Nature's heart beats night and day.  \n",
            "\n",
            "Steel and stone, a city's might,  \n",
            "But stars still shine in velvet night.  \n",
            "A balance sought, in harmony,  \n",
            "Where tech and earth can both be free.  \n",
            "\n",
            "So let us weave, with mindful thread,  \n",
            "A future where both paths are led.  \n",
            "In every byte, and every tree,  \n",
            "A world united, you and me.\n",
            "\n",
            "---\n",
            "\n",
            "Creative settings (temperature=0.9):\n",
            "\n",
            "In the cradle of the forest, whispers hum,  \n",
            "Where circuits pulse and machines softly thrum.  \n",
            "Nature's breath mingles with silicon's sigh,  \n",
            "Underneath the digital sprawl of the sky.  \n",
            "\n",
            "Trees weave shadows while data flows bright,  \n",
            "Stars blink their secrets, illuminating night.  \n",
            "Harmony dances in a delicate blend,  \n",
            "Where wires touch roots, and both hearts mend.  \n",
            "\n",
            "With every heartbeat, a promise to share,  \n",
            "The beauty of both, a world beyond compare.  \n",
            "In this union of life, both ancient and new,  \n",
            "Technology blooms in nature's embrace, true.\n"
          ]
        }
      ],
      "source": [
        "# Function to demonstrate different parameter settings\n",
        "def compare_parameters(prompt):\n",
        "    print(f\"Prompt: {prompt}\\n\")\n",
        "\n",
        "    # Conservative settings (more deterministic)\n",
        "    conservative = client.chat.completions.create(\n",
        "        model='sutra-v2',\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=1024,\n",
        "        temperature=0.3,\n",
        "        top_p=0.85,\n",
        "        frequency_penalty=0.0,\n",
        "        presence_penalty=0.0\n",
        "    )\n",
        "\n",
        "    # Creative settings (more random)\n",
        "    creative = client.chat.completions.create(\n",
        "        model='sutra-v2',\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=1024,\n",
        "        temperature=0.9,\n",
        "        top_p=0.95,\n",
        "        frequency_penalty=0.5,\n",
        "        presence_penalty=0.5\n",
        "    )\n",
        "\n",
        "    print(\"Conservative settings (temperature=0.3):\\n\")\n",
        "    print(conservative.choices[0].message.content)\n",
        "    print(\"\\n---\\n\")\n",
        "    print(\"Creative settings (temperature=0.9):\\n\")\n",
        "    print(creative.choices[0].message.content)\n",
        "\n",
        "# Try with a creative prompt\n",
        "compare_parameters(\"Write a short poem about technology and nature.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chatbot_header"
      },
      "source": [
        "## Step 7: Building a Simple Chatbot\n",
        "\n",
        "Create a basic chatbot that maintains conversation history:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264,
          "referenced_widgets": [
            "24378468f6304949af8e3221e91cd677",
            "0f063e4b3d11407c91f3fc73a00f02f7",
            "e5fc753c81bc4f49b792d739bec7dd3c",
            "84538336567941d7bd820ccef2278cf8",
            "41b76041263d4a7eb5457b10820b9d8f",
            "ac354aa1cf2f4ca9b5563d9059063a78",
            "b36ab2af89d9407aafd585b73f617271",
            "14e3a174c1b240e6bde20759955671e7",
            "130eac94efa1402a97a1412d9e2a25bf",
            "58b5631e04ef48e48f3c55e44454480e",
            "2ed550bf1b274bdb9807315f50b5fbc3",
            "5fffca1a50194186b1e8b977457dc429"
          ]
        },
        "id": "chatbot_code",
        "outputId": "74613f29-7c91-4a74-d523-d893debb9e7e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<h3>Chat with SUTRA</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24378468f6304949af8e3221e91cd677",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Output(), HBox(children=(Text(value='', placeholder='Type your message here...'), Button(descriâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "conversation_history = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant powered by SUTRA. You are knowledgeable, friendly, and concise.\"}\n",
        "]\n",
        "\n",
        "def chat(user_input):\n",
        "    # Add the user's message to the conversation\n",
        "    conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # Get the response from SUTRA\n",
        "    response = client.chat.completions.create(\n",
        "        model='sutra-v2',\n",
        "        messages=conversation_history,\n",
        "        max_tokens=1024,\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    # Extract the assistant's reply\n",
        "    assistant_response = response.choices[0].message.content\n",
        "\n",
        "    # Add the assistant's response to the conversation history\n",
        "    conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
        "\n",
        "    return assistant_response\n",
        "\n",
        "# Interactive chat interface\n",
        "from IPython.display import display, HTML\n",
        "import ipywidgets as widgets\n",
        "\n",
        "output = widgets.Output()\n",
        "input_box = widgets.Text(placeholder='Type your message here...')\n",
        "\n",
        "def on_send(b):\n",
        "    user_input = input_box.value\n",
        "    input_box.value = ''\n",
        "\n",
        "    with output:\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style='background-color:#ffffff; color:#000000; padding:10px; margin:5px; border-radius:5px;'>\n",
        "            <b>You:</b> {user_input}\n",
        "        </div>\"\"\"))\n",
        "        response = chat(user_input)\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style='background-color:#ffffff; color:#000000; padding:10px; margin:5px; border-radius:5px;'>\n",
        "            <b>SUTRA:</b> {response}\n",
        "        </div>\"\"\"))\n",
        "\n",
        "send_button = widgets.Button(description=\"Send\")\n",
        "send_button.on_click(on_send)\n",
        "\n",
        "def on_enter(widget):\n",
        "    on_send(None)\n",
        "\n",
        "input_box.on_submit(on_enter)\n",
        "\n",
        "display(HTML(\"<h3>Chat with SUTRA</h3>\"))\n",
        "display(widgets.VBox([output, widgets.HBox([input_box, send_button])]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "langchain_header"
      },
      "source": [
        "## Step 8: Integration with LangChain\n",
        "\n",
        "For more complex applications, you can integrate SUTRA with LangChain:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "langchain_install",
        "outputId": "a121fb1e-3beb-4ed7-c7ea-f6b9a36f52de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.5/2.5 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/44.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/50.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hâœ… LangChain installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Install LangChain\n",
        "!pip install -qU langchain langchain-openai langchain_community\n",
        "print(\"âœ… LangChain installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "langchain_code",
        "outputId": "2ca21d45-cfbc-4759-ec68-0932277a46fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangChain + SUTRA response:\n",
            "\n",
            "Why do programmers prefer dark mode?\n",
            "\n",
            "Because light attracts bugs!\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "\n",
        "# Initialize the LangChain ChatOpenAI with SUTRA\n",
        "chat = ChatOpenAI(\n",
        "    model=\"sutra-v2\",\n",
        "    api_key=api_key,  # Use your actual API key\n",
        "    base_url=\"https://api.two.ai/v2\"\n",
        ")\n",
        "\n",
        "# Define messages\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant that provides concise answers.\"),\n",
        "    HumanMessage(content=\"Tell me a joke about programming.\")\n",
        "]\n",
        "\n",
        "# Get and print the response\n",
        "response = chat.invoke(messages)\n",
        "print(\"LangChain + SUTRA response:\\n\")\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion_cell"
      },
      "source": [
        "## Troubleshooting\n",
        "\n",
        "If you encounter issues:\n",
        "\n",
        "1. **Authentication Errors**: Verify your API key is correct and properly set\n",
        "2. **Rate Limiting**: Check if you've exceeded your API usage limits\n",
        "3. **Connection Issues**: Ensure you have internet connectivity and the API endpoint is accessible\n",
        "4. **Response Format**: Make sure you're correctly parsing the response object\n",
        "\n",
        "\n",
        "## Resources\n",
        "\n",
        "- [Official Documentation](https://docs.two.ai/version-2/docs/get-started-with-sutra)\n",
        "- [TWO AI Website](https://www.two.ai)\n",
        "- [Follow TWO AI on Twitter](https://twitter.com/two_platforms)\n",
        "\n",
        "---\n",
        "\n",
        "Â© 2025 TWO AI | All Rights Reserved"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
