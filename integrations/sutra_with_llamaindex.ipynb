{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zIiYGJZZOsH"
      },
      "source": [
        "<div style=\"display: flex; align-items: center; gap: 40px;\">\n",
        "\n",
        "<img src=\"https://play-lh.googleusercontent.com/_O9p4Z4yucA2NLmZBu9mTJCuBwXeT9NcbtrDN6I8gKlkIPRySV0adOmbyipjSj9Gew\" width=\"130\"><img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQmC5gqclRICsDUVYV9uQXVaIfH3gCapSdjEQ&s\" width=\"130\">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<div>\n",
        "  <h2>SUTRA by TWO Platforms </h2>\n",
        "  <p>SUTRA is a family of large multi-lingual language (LMLMs) models pioneered by Two Platforms. SUTRA‚Äôs dual-transformer approach extends the power of both MoE and Dense AI language model architectures, delivering cost-efficient multilingual capabilities for over 50+ languages. It powers scalable AI applications for conversation, search, and advanced reasoning, ensuring high-performance across diverse languages, domains and applications.</p>\n",
        "\n",
        "  <h2>LlamaIndex ü¶ô</h2>\n",
        "  <p>LlamaIndex is the leading framework for building LLM-powered agents over your data with LLMs and workflows.</p>\n",
        "</div>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1IzEMvNDPmPa8OWYLUn2Y_7XA-xq1UUKX?usp=sharing#scrollTo=468wYMncagrN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get Your API Keys\n",
        "\n",
        "Before you begin, make sure you have:\n",
        "\n",
        "1. A SUTRA API key (Get yours at [TWO AI's SUTRA API page](https://www.two.ai/sutra/api))\n",
        "2. Basic familiarity with Python and Jupyter notebooks\n",
        "\n",
        "This notebook is designed to run in Google Colab, so no local Python installation is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "468wYMncagrN"
      },
      "source": [
        "###Sutra using LlamaIndex ü¶ô"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMn1dXjgamFU"
      },
      "source": [
        "###Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_62EQccD-Fx",
        "outputId": "309d91fe-abab-47c2-aa96-b36f3fc13462"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m263.6/263.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU llama-index llama-index-llms-openai-like llama-index-vector-stores-faiss faiss-cpu ipywidgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8Gq3jNOap6J"
      },
      "source": [
        "###Setup API Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "He-gNIfuE_bw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set the API key from Colab secrets\n",
        "os.environ[\"SUTRA_API_KEY\"] = userdata.get(\"SUTRA_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c33niB0avy1"
      },
      "source": [
        "###Initialize Sutra Model via LlamaIndex ü¶ô:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IK3ffJhpREuA",
        "outputId": "cc4df1ac-d228-4ba0-8805-d53e00340d88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‡§Æ‡•à‡§Ç ‡§†‡•Ä‡§ï ‡§π‡•Ç‡§Å, ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶! ‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç?\n"
          ]
        }
      ],
      "source": [
        "from llama_index.llms.openai_like import OpenAILike\n",
        "\n",
        "# Initialize Sutra LLM with necessary parameters\n",
        "llm = OpenAILike(\n",
        "    model=\"sutra-v2\",                    # Sutra model name\n",
        "    api_base=\"https://api.two.ai/v2\",    # Sutra API base URL\n",
        "    api_key=os.getenv(\"SUTRA_API_KEY\"),  # Sutra API key\n",
        "    is_chat_model=True,                  # Mandatory: Set to True for chat-based models\n",
        ")\n",
        "\n",
        "# Send request and print response\n",
        "response = llm.complete(\"‡§ï‡•à‡§∏‡•á ‡§π‡•ã?\")       # Sending a message to the model in Hindi (\"How are you?\")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynnSF9pka4uh"
      },
      "source": [
        "###Multilingual capabilities using LlamaIndex ü¶ô"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNO6tVCvSXfh",
        "outputId": "ce4cce5e-9567-426c-d492-7ddf9536634f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Prompt: ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å‡∞≤‡±ã ‡∞í‡∞ï ‡∞ï‡∞• ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡±Å?\n",
            "Response: ‡∞í‡∞ï ‡∞ó‡±ç‡∞∞‡∞æ‡∞Æ‡∞Ç‡∞≤‡±ã ‡∞í‡∞ï ‡∞ö‡∞ø‡∞®‡±ç‡∞® ‡∞™‡∞ø‡∞≤‡±ç‡∞≤‡∞µ‡∞æ‡∞°‡±Å ‡∞â‡∞Ç‡∞°‡±á‡∞µ‡∞æ‡∞°‡±Å. ‡∞Ö‡∞§‡∞®‡∞ø ‡∞™‡±á‡∞∞‡±Å ‡∞∞‡∞æ‡∞Æ‡±ç. ‡∞∞‡∞æ‡∞Æ‡±ç ‡∞ö‡∞æ‡∞≤‡∞æ ‡∞ö‡±Å‡∞∞‡±Å‡∞ï‡±Å‡∞ó‡∞æ ‡∞â‡∞Ç‡∞°‡±á‡∞µ‡∞æ‡∞°‡±Å, ‡∞ï‡∞æ‡∞®‡±Ä ‡∞Ö‡∞§‡∞®‡∞ø‡∞ï‡∞ø ‡∞ö‡∞¶‡±Å‡∞µ‡±Å‡∞≤‡±ã ‡∞Ü‡∞∏‡∞ï‡±ç‡∞§‡∞ø ‡∞≤‡±á‡∞¶‡±Å. ‡∞Ö‡∞§‡∞®‡±Å ‡∞é‡∞™‡±ç‡∞™‡±Å‡∞°‡±Ç ‡∞Ü‡∞ü‡∞≤‡∞≤‡±ã‡∞®‡±á ‡∞Æ‡±Å‡∞®‡∞ø‡∞ó‡∞ø‡∞™‡±ã‡∞Ø‡±á‡∞µ‡∞æ‡∞°‡±Å. \n",
            "\n",
            "‡∞í‡∞ï ‡∞∞‡±ã‡∞ú‡±Å, ‡∞∞‡∞æ‡∞Æ‡±ç ‡∞§‡∞® ‡∞∏‡±ç‡∞®‡±á‡∞π‡∞ø‡∞§‡±Å‡∞≤‡∞§‡±ã ‡∞ï‡∞≤‡∞ø‡∞∏‡∞ø ‡∞Ö‡∞°‡∞µ‡∞ø‡∞≤‡±ã‡∞ï‡∞ø ‡∞µ‡±Ü‡∞≥‡±ç‡∞≤‡∞æ‡∞°‡±Å. ‡∞Ö‡∞ï‡±ç‡∞ï‡∞° ‡∞µ‡∞æ‡∞∞‡±Å ‡∞í‡∞ï ‡∞™‡∞æ‡∞§ ‡∞ö‡±Ü‡∞ü‡±ç‡∞ü‡±Å ‡∞ï‡∞ø‡∞Ç‡∞¶ ‡∞ï‡±Ç‡∞∞‡±ç‡∞ö‡±ä‡∞®‡∞ø ‡∞Ü‡∞ü‡∞≤‡±Å ‡∞Ü‡∞°‡±Å‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞∞‡±Å. ‡∞Ü ‡∞∏‡∞Æ‡∞Ø‡∞Ç‡∞≤‡±ã, ‡∞∞‡∞æ‡∞Æ‡±ç ‡∞Ü ‡∞ö‡±Ü‡∞ü‡±ç‡∞ü‡±Å‡∞ï‡±Å ‡∞¶‡∞ó‡±ç‡∞ó‡∞∞‡∞ó‡∞æ ‡∞µ‡±Ü‡∞≥‡±ç‡∞≤‡∞ø, ‡∞¶‡∞æ‡∞®‡∞ø ‡∞ï‡±ä‡∞Æ‡±ç‡∞Æ‡∞≤‡∞®‡±Å ‡∞ö‡±Ç‡∞∏‡∞æ‡∞°‡±Å. ‡∞Ö‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞Ö‡∞§‡∞®‡∞ø‡∞ï‡∞ø ‡∞Ü ‡∞ö‡±Ü‡∞ü‡±ç‡∞ü‡±Å ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞§‡±Ü‡∞≤‡±Å‡∞∏‡±Å‡∞ï‡±ã‡∞µ‡∞æ‡∞≤‡∞®‡∞ø‡∞™‡∞ø‡∞Ç‡∞ö‡∞ø‡∞Ç‡∞¶‡∞ø. \n",
            "\n",
            "‡∞Ö‡∞§‡∞®‡±Å ‡∞Ö‡∞°‡∞µ‡∞ø‡∞≤‡±ã ‡∞â‡∞®‡±ç‡∞® ‡∞™‡±Ü‡∞¶‡±ç‡∞¶‡∞µ‡∞æ‡∞∞‡∞ø‡∞®‡∞ø ‡∞Ö‡∞°‡∞ø‡∞ó‡∞æ‡∞°‡±Å, \"‡∞à ‡∞ö‡±Ü‡∞ü‡±ç‡∞ü‡±Å ‡∞é‡∞Ç‡∞§ ‡∞™‡∞æ‡∞§‡∞¶‡∞ø?\" ‡∞™‡±Ü‡∞¶‡±ç‡∞¶‡∞µ‡∞æ‡∞°‡±Å ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç ‡∞á‡∞ö‡±ç‡∞ö‡∞æ‡∞°‡±Å, \"‡∞à ‡∞ö‡±Ü‡∞ü‡±ç‡∞ü‡±Å ‡∞µ‡∞Ç‡∞¶ ‡∞∏‡∞Ç‡∞µ‡∞§‡±ç‡∞∏‡∞∞‡∞æ‡∞≤ ‡∞™‡∞æ‡∞§‡∞¶‡∞ø. ‡∞á‡∞¶‡∞ø ‡∞é‡∞®‡±ç‡∞®‡±ã ‡∞ï‡∞•‡∞≤‡±Å ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞ó‡∞≤‡∞¶‡±Å.\" \n",
            "\n",
            "‡∞∞‡∞æ‡∞Æ‡±ç ‡∞Ü ‡∞ö‡±Ü‡∞ü‡±ç‡∞ü‡±Å‡∞ï‡±Å ‡∞¶‡∞ó‡±ç‡∞ó‡∞∞‡∞ó‡∞æ ‡∞µ‡±Ü‡∞≥‡±ç‡∞≤‡∞ø, \"‡∞®‡±á‡∞®‡±Å ‡∞®‡±Ä ‡∞ï‡∞•‡∞≤‡±Å ‡∞µ‡∞ø‡∞®‡∞æ‡∞≤‡∞®‡±Å‡∞ï‡±Å‡∞Ç‡∞ü‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞®‡±Å\" ‡∞Ö‡∞®‡∞ø ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞æ‡∞°‡±Å. ‡∞Ö‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞ö‡±Ü‡∞ü‡±ç‡∞ü‡±Å ‡∞í‡∞ï ‡∞Æ‡∞æ‡∞Ø‡∞æ‡∞ú‡∞æ‡∞≤‡∞Ç‡∞≤‡±ã‡∞ï‡∞ø ‡∞Æ‡∞æ‡∞∞‡∞ø‡∞Ç‡∞¶‡∞ø. ‡∞ö‡±Ü‡∞ü‡±ç‡∞ü‡±Å ‡∞Æ‡∞æ‡∞ü‡±ç‡∞≤‡∞æ‡∞°‡∞ü‡∞Ç ‡∞™‡±ç‡∞∞‡∞æ‡∞∞‡∞Ç‡∞≠‡∞ø‡∞Ç‡∞ö‡∞ø‡∞Ç‡∞¶‡∞ø. \"‡∞®‡±á‡∞®‡±Å ‡∞é‡∞®‡±ç‡∞®‡±ã ‡∞ï‡∞æ‡∞≤‡∞æ‡∞≤ ‡∞®‡±Å‡∞Ç‡∞°‡∞ø ‡∞á‡∞ï‡±ç‡∞ï‡∞° ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞®‡±Å. ‡∞®‡±á‡∞®‡±Å ‡∞ö‡±Ç‡∞∏‡∞ø‡∞® ‡∞Ö‡∞®‡±á‡∞ï ‡∞∏‡∞Ç‡∞ò‡∞ü‡∞®‡∞≤‡±Å, ‡∞™‡±ç‡∞∞‡±á‡∞Æ, ‡∞Ø‡±Å‡∞¶‡±ç‡∞ß‡∞æ‡∞≤‡±Å, ‡∞Ü‡∞®‡∞Ç‡∞¶‡∞Ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞¶‡±Å‡∞É‡∞ñ‡∞Ç ‡∞Ö‡∞®‡±ç‡∞®‡±Ä ‡∞®‡∞æ‡∞ï‡±Å ‡∞ó‡±Å‡∞∞‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Ø‡∞ø.\"\n",
            "\n",
            "‡∞∞‡∞æ‡∞Æ‡±ç ‡∞ö‡±Ü‡∞ü‡±ç‡∞ü‡±Å‡∞§‡±ã ‡∞Æ‡∞æ‡∞ü‡±ç‡∞≤‡∞æ‡∞°‡∞ø, ‡∞Ö‡∞Ç‡∞¶‡±Å‡∞≤‡±ã‡∞®‡∞ø ‡∞ú‡±ç‡∞û‡∞æ‡∞®‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞§‡±Ü‡∞≤‡±Å‡∞∏‡±Å‡∞ï‡±ã‡∞µ‡∞æ‡∞≤‡∞®‡∞ø ‡∞®‡∞ø‡∞∞‡±ç‡∞£‡∞Ø‡∞ø‡∞Ç‡∞ö‡±Å‡∞ï‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞°‡±Å. ‡∞∞‡±ã‡∞ú‡±Å‡∞≤‡±Å ‡∞ó‡∞°‡∞ø‡∞ö‡∞æ‡∞Ø‡∞ø, ‡∞∞‡∞æ‡∞Æ‡±ç ‡∞™‡±ç‡∞∞‡∞§‡∞ø‡∞∞‡±ã‡∞ú‡±Ç ‡∞ö‡±Ü‡∞ü‡±ç‡∞ü‡±Å‡∞ï‡±Å ‡∞µ‡∞ö‡±ç‡∞ö‡∞ø ‡∞ï‡±ä‡∞§‡±ç‡∞§ ‡∞µ‡∞ø‡∞∑‡∞Ø‡∞æ‡∞≤‡±Å ‡∞§‡±Ü‡∞≤‡±Å‡∞∏‡±Å‡∞ï‡±Å‡∞®‡±á ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞Ç ‡∞ö‡±á‡∞∂‡∞æ‡∞°‡±Å. \n",
            "\n",
            "‡∞ö‡±Ü‡∞ü‡±ç‡∞ü‡±Å ‡∞∞‡∞æ‡∞Æ‡±ç‚Äå‡∞ï‡±Å ‡∞ö‡∞¶‡±Å‡∞µ‡±Å, ‡∞ú‡±Ä‡∞µ‡∞ø‡∞§‡∞Ç, ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞∏‡±ç‡∞®‡±á‡∞π‡∞Ç ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞é‡∞®‡±ç‡∞®‡±ã ‡∞™‡∞æ‡∞†‡∞æ‡∞≤‡±Å ‡∞®‡±á‡∞∞‡±ç‡∞™‡∞ø‡∞Ç‡∞ö‡∞ø‡∞Ç‡∞¶‡∞ø. ‡∞ö‡∞ø‡∞µ‡∞∞‡∞ï‡±Å, ‡∞∞‡∞æ‡∞Æ‡±ç ‡∞ö‡∞¶‡±Å‡∞µ‡±Å‡∞≤‡±ã ‡∞Ü‡∞∏‡∞ï‡±ç‡∞§‡∞ø ‡∞™‡±Ü‡∞Ç‡∞ö‡±Å‡∞ï‡±Å‡∞®‡∞ø, ‡∞Æ‡∞Ç‡∞ö‡∞ø ‡∞µ‡∞ø‡∞¶‡±ç‡∞Ø‡∞æ‡∞∞‡±ç‡∞•‡∞ø‡∞ó‡∞æ ‡∞Æ‡∞æ‡∞∞‡∞æ‡∞°‡±Å. \n",
            "\n",
            "‡∞à ‡∞µ‡∞ø‡∞ß‡∞Ç‡∞ó‡∞æ, ‡∞ö‡±Ü‡∞ü‡±ç‡∞ü‡±Å ‡∞¶‡±ç‡∞µ‡∞æ‡∞∞‡∞æ ‡∞∞‡∞æ‡∞Æ‡±ç ‡∞§‡∞® ‡∞ú‡±Ä‡∞µ‡∞ø‡∞§‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ö‡±Å‡∞ï‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞°‡±Å. ‡∞Ö‡∞§‡∞®‡±Å ‡∞ó‡±ç‡∞∞‡∞π‡∞ø‡∞Ç‡∞ö‡∞æ‡∞°‡±Å, ‡∞ú‡±ç‡∞û‡∞æ‡∞®‡∞Ç ‡∞™‡±ä‡∞Ç‡∞¶‡∞°‡∞Ç ‡∞é‡∞Ç‡∞§ ‡∞Æ‡±Å‡∞ñ‡±ç‡∞Ø‡∞Æ‡±ã. \n",
            "\n",
            "‡∞à ‡∞ï‡∞• ‡∞Æ‡∞®‡∞ï‡±Å ‡∞§‡±Ü‡∞≤‡∞ø‡∞Ø‡∞ú‡±á‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø, ‡∞ú‡±ç‡∞û‡∞æ‡∞®‡∞Ç ‡∞é‡∞ï‡±ç‡∞ï‡∞°‡∞ø ‡∞®‡±Å‡∞Ç‡∞ö‡±à‡∞®‡∞æ ‡∞∞‡∞æ‡∞µ‡∞ö‡±ç‡∞ö‡±Å, ‡∞ï‡∞æ‡∞¨‡∞ü‡±ç‡∞ü‡∞ø ‡∞Æ‡∞®‡∞Ç ‡∞é‡∞™‡±ç‡∞™‡±Å‡∞°‡±Ç ‡∞®‡±á‡∞∞‡±ç‡∞ö‡±Å‡∞ï‡±ã‡∞µ‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∏‡∞ø‡∞¶‡±ç‡∞ß‡∞Ç‡∞ó‡∞æ ‡∞â‡∞Ç‡∞°‡∞æ‡∞≤‡∞ø.\n",
            "\n",
            "\n",
            "Prompt: Une histoire en fran√ßais, s'il vous pla√Æt.\n",
            "Response: Il √©tait une fois, dans un petit village nich√© au c≈ìur des montagnes, une jeune fille nomm√©e √âlodie. √âlodie avait un r√™ve : explorer le monde au-del√† des sommets qui entouraient son village. Chaque jour, elle s'asseyait pr√®s de la fen√™tre de sa chambre, regardant les nuages flotter et imaginant les aventures qui l'attendaient.\n",
            "\n",
            "Un matin, alors qu'elle se promenait dans la for√™t voisine, √âlodie d√©couvrit un vieux livre en cuir cach√© sous un tas de feuilles. Curieuse, elle l'ouvrit et trouva des histoires de contr√©es lointaines, de cr√©atures fantastiques et de tr√©sors cach√©s. En lisant ces r√©cits, son d√©sir d'aventure grandit encore plus.\n",
            "\n",
            "D√©cid√©e √† r√©aliser son r√™ve, √âlodie commen√ßa √† pr√©parer son voyage. Elle rassembla quelques provisions, une carte ancienne qu'elle avait trouv√©e dans le grenier de sa grand-m√®re, et un petit m√©daillon que sa m√®re lui avait offert pour la prot√©ger. Le lendemain, elle se leva avant l'aube et, avec un c≈ìur plein d'espoir, elle quitta son village.\n",
            "\n",
            "Au cours de son p√©riple, √âlodie rencontra des personnages fascinants : un sage ermite qui lui enseigna la patience, une troupe de musiciens itin√©rants qui lui apprirent la joie de vivre, et un jeune gar√ßon nomm√© Lucas, qui devint son fid√®le compagnon. Ensemble, ils affront√®rent des temp√™tes, travers√®rent des rivi√®res tumultueuses et escalad√®rent des montagnes escarp√©es.\n",
            "\n",
            "Un jour, alors qu'ils exploraient une grotte myst√©rieuse, ils d√©couvrirent un tr√©sor cach√© : des pierres pr√©cieuses scintillantes et des artefacts anciens. Mais au lieu de garder ce tr√©sor pour eux, √âlodie et Lucas d√©cid√®rent de le ramener au village pour partager leur d√©couverte avec tous. Ils savaient que la v√©ritable richesse r√©sidait dans les liens qu'ils avaient tiss√©s et les exp√©riences v√©cues ensemble.\n",
            "\n",
            "De retour chez elle, √âlodie fut accueillie en h√©ro√Øne. Elle raconta ses aventures, inspirant les autres villageois √† poursuivre leurs propres r√™ves. Gr√¢ce √† son courage et √† sa d√©termination, le village devint un lieu o√π chacun osait r√™ver et explorer.\n",
            "\n",
            "Et ainsi, √âlodie comprit que le voyage √©tait tout aussi important que la destination. Elle continua √† explorer le monde, mais toujours avec le souvenir de son village et des amis qu'elle avait rencontr√©s en chemin.\n",
            "\n",
            "\n",
            "Prompt: Por favor, cu√©ntame una historia en espa√±ol.\n",
            "Response: Hab√≠a una vez en un peque√±o pueblo llamado Valle Verde, un joven llamado Lucas que so√±aba con ser aventurero. Desde ni√±o, pasaba horas leyendo libros sobre exploradores y tierras lejanas. Sin embargo, su vida en el pueblo era tranquila y mon√≥tona, rodeado de monta√±as y r√≠os que nunca hab√≠a explorado.\n",
            "\n",
            "Un d√≠a, mientras caminaba por el bosque cercano, Lucas encontr√≥ un viejo mapa escondido entre las ra√≠ces de un √°rbol. El mapa mostraba un camino hacia una cueva misteriosa en la monta√±a m√°s alta del valle. Intrigado, decidi√≥ que era el momento de vivir la aventura que siempre hab√≠a deseado.\n",
            "\n",
            "Al amanecer del d√≠a siguiente, Lucas se prepar√≥ con provisiones y comenz√≥ su viaje. A medida que ascend√≠a por la monta√±a, se encontr√≥ con diversos desaf√≠os: r√≠os caudalosos que cruzar, rocas resbaladizas y animales salvajes. Pero cada obst√°culo lo hac√≠a m√°s fuerte y decidido.\n",
            "\n",
            "Finalmente, despu√©s de d√≠as de arduo esfuerzo, lleg√≥ a la entrada de la cueva. Con el coraz√≥n latiendo con fuerza, encendi√≥ una antorcha y entr√≥. Dentro, descubri√≥ pinturas rupestres que contaban historias de antiguos habitantes del valle y un cofre lleno de tesoros olvidados: joyas, monedas de oro y objetos m√°gicos.\n",
            "\n",
            "Lucas comprendi√≥ que su aventura no solo le hab√≠a tra√≠do riquezas materiales, sino tambi√©n un profundo conocimiento sobre su historia y cultura. Decidi√≥ regresar al pueblo y compartir sus hallazgos con todos. Se convirti√≥ en un h√©roe local, inspirando a otros a explorar y valorar su entorno.\n",
            "\n",
            "Desde entonces, Valle Verde se llen√≥ de nuevas aventuras, y Lucas nunca dej√≥ de buscar nuevas historias que contar. As√≠, el joven so√±ador se transform√≥ en un verdadero aventurero, recordando siempre que la mayor riqueza est√° en las experiencias vividas y en el conocimiento adquirido.\n",
            "\n",
            "\n",
            "Prompt: ‡§ï‡•É‡§™‡§Ø‡§æ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§ï‡§π‡§æ‡§®‡•Ä ‡§∏‡•Å‡§®‡§æ‡§á‡§è‡•§\n",
            "Response: ‡§è‡§ï ‡§¨‡§æ‡§∞ ‡§ï‡•Ä ‡§¨‡§æ‡§§ ‡§π‡•à, ‡§è‡§ï ‡§õ‡•ã‡§ü‡•á ‡§∏‡•á ‡§ó‡§æ‡§Å‡§µ ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§ï‡§ø‡§∏‡§æ‡§® ‡§∞‡§π‡§§‡§æ ‡§•‡§æ‡•§ ‡§â‡§∏‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§∞‡§æ‡§Æ‡•Ç ‡§•‡§æ‡•§ ‡§∞‡§æ‡§Æ‡•Ç ‡§¨‡§π‡•Å‡§§ ‡§Æ‡•á‡§π‡§®‡§§‡•Ä ‡§î‡§∞ ‡§à‡§Æ‡§æ‡§®‡§¶‡§æ‡§∞ ‡§ï‡§ø‡§∏‡§æ‡§® ‡§•‡§æ, ‡§≤‡•á‡§ï‡§ø‡§® ‡§â‡§∏‡§ï‡•Ä ‡§´‡§∏‡§≤ ‡§π‡§Æ‡•á‡§∂‡§æ ‡§ñ‡§∞‡§æ‡§¨ ‡§π‡•ã‡§§‡•Ä ‡§•‡•Ä‡•§ ‡§ó‡§æ‡§Å‡§µ ‡§ï‡•á ‡§≤‡•ã‡§ó ‡§â‡§∏‡•á ‡§Æ‡§ú‡§æ‡§ï ‡§â‡§°‡§º‡§æ‡§§‡•á ‡§•‡•á, ‡§≤‡•á‡§ï‡§ø‡§® ‡§∞‡§æ‡§Æ‡•Ç ‡§ï‡§≠‡•Ä ‡§π‡§æ‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§æ‡§®‡§§‡§æ ‡§•‡§æ‡•§\n",
            "\n",
            "‡§è‡§ï ‡§¶‡§ø‡§®, ‡§∞‡§æ‡§Æ‡•Ç ‡§®‡•á ‡§∏‡•ã‡§ö‡§æ ‡§ï‡§ø ‡§â‡§∏‡•á ‡§ï‡•Å‡§õ ‡§®‡§Ø‡§æ ‡§ï‡§∞‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è‡•§ ‡§â‡§∏‡§®‡•á ‡§ó‡§æ‡§Å‡§µ ‡§ï‡•á ‡§™‡•Å‡§∞‡§æ‡§®‡•á ‡§™‡•Å‡§∏‡•ç‡§§‡§ï‡§æ‡§≤‡§Ø ‡§∏‡•á ‡§ï‡•É‡§∑‡§ø ‡§™‡§∞ ‡§ï‡•Å‡§õ ‡§ï‡§ø‡§§‡§æ‡§¨‡•á‡§Ç ‡§™‡§¢‡§º‡•Ä‡§Ç‡•§ ‡§â‡§® ‡§ï‡§ø‡§§‡§æ‡§¨‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§â‡§∏‡•á ‡§™‡§§‡§æ ‡§ö‡§≤‡§æ ‡§ï‡§ø ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§ï‡•Ä ‡§ó‡•Å‡§£‡§µ‡§§‡•ç‡§§‡§æ ‡§î‡§∞ ‡§´‡§∏‡§≤ ‡§ö‡§ï‡•ç‡§∞ ‡§ï‡§æ ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§∞‡§ñ‡§®‡§æ ‡§ï‡§ø‡§§‡§®‡§æ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•à‡•§ ‡§â‡§∏‡§®‡•á ‡§Ö‡§™‡§®‡•á ‡§ñ‡•á‡§§ ‡§Æ‡•á‡§Ç ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§®‡•á ‡§ï‡§æ ‡§®‡§ø‡§∞‡•ç‡§£‡§Ø ‡§≤‡§ø‡§Ø‡§æ‡•§\n",
            "\n",
            "‡§∞‡§æ‡§Æ‡•Ç ‡§®‡•á ‡§™‡§π‡§≤‡•á ‡§Ö‡§™‡§®‡•Ä ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§ï‡•Ä ‡§ú‡§æ‡§Ç‡§ö ‡§ï‡§∞‡§µ‡§æ‡§à ‡§î‡§∞ ‡§â‡§∏‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§ñ‡§æ‡§¶ ‡§î‡§∞ ‡§¨‡•Ä‡§ú ‡§ï‡§æ ‡§ö‡§Ø‡§® ‡§ï‡§ø‡§Ø‡§æ‡•§ ‡§â‡§∏‡§®‡•á ‡§´‡§∏‡§≤ ‡§ö‡§ï‡•ç‡§∞ ‡§Ö‡§™‡§®‡§æ‡§Ø‡§æ ‡§î‡§∞ ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§ï‡•Ä ‡§´‡§∏‡§≤‡•á‡§Ç ‡§â‡§ó‡§æ‡§®‡•á ‡§ï‡§æ ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ï‡§ø‡§Ø‡§æ‡•§ ‡§ß‡•Ä‡§∞‡•á-‡§ß‡•Ä‡§∞‡•á, ‡§â‡§∏‡§ï‡•Ä ‡§Æ‡•á‡§π‡§®‡§§ ‡§∞‡§Ç‡§ó ‡§≤‡§æ‡§à‡•§ ‡§â‡§∏‡§ï‡•Ä ‡§´‡§∏‡§≤‡•á‡§Ç ‡§Ö‡§¨ ‡§π‡§∞ ‡§∏‡§æ‡§≤ ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§π‡•ã‡§®‡•á ‡§≤‡§ó‡•Ä‡§Ç‡•§\n",
            "\n",
            "‡§ó‡§æ‡§Å‡§µ ‡§ï‡•á ‡§≤‡•ã‡§ó ‡§Ö‡§¨ ‡§∞‡§æ‡§Æ‡•Ç ‡§ï‡•Ä ‡§§‡§æ‡§∞‡•Ä‡§´ ‡§ï‡§∞‡§®‡•á ‡§≤‡§ó‡•á‡•§ ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§¶‡•á‡§ñ‡§æ ‡§ï‡§ø ‡§ï‡•à‡§∏‡•á ‡§∞‡§æ‡§Æ‡•Ç ‡§®‡•á ‡§Ö‡§™‡§®‡•Ä ‡§Æ‡•á‡§π‡§®‡§§ ‡§î‡§∞ ‡§ú‡•ç‡§û‡§æ‡§® ‡§∏‡•á ‡§Ö‡§™‡§®‡•Ä ‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§ï‡•ã ‡§¨‡§¶‡§≤ ‡§¶‡§ø‡§Ø‡§æ‡•§ ‡§∞‡§æ‡§Æ‡•Ç ‡§®‡•á ‡§® ‡§ï‡•á‡§µ‡§≤ ‡§Ö‡§™‡§®‡•Ä ‡§´‡§∏‡§≤‡•á‡§Ç ‡§¨‡§¢‡§º‡§æ‡§à‡§Ç, ‡§¨‡§≤‡•ç‡§ï‡§ø ‡§ó‡§æ‡§Å‡§µ ‡§ï‡•á ‡§Ö‡§®‡•ç‡§Ø ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•ã ‡§≠‡•Ä ‡§Ö‡§™‡§®‡•á ‡§Ö‡§®‡•Å‡§≠‡§µ ‡§∏‡§æ‡§ù‡§æ ‡§ï‡§ø‡§è‡•§ \n",
            "\n",
            "‡§á‡§∏ ‡§§‡§∞‡§π, ‡§∞‡§æ‡§Æ‡•Ç ‡§®‡•á ‡§® ‡§ï‡•á‡§µ‡§≤ ‡§Ö‡§™‡§®‡•Ä ‡§ú‡§ø‡§Ç‡§¶‡§ó‡•Ä ‡§¨‡§¶‡§≤‡•Ä, ‡§¨‡§≤‡•ç‡§ï‡§ø ‡§™‡•Ç‡§∞‡•á ‡§ó‡§æ‡§Å‡§µ ‡§ï‡•ã ‡§è‡§ï ‡§®‡§à ‡§¶‡§ø‡§∂‡§æ ‡§¶‡§ø‡§ñ‡§æ‡§à‡•§ ‡§â‡§∏‡§ï‡•Ä ‡§ï‡§π‡§æ‡§®‡•Ä ‡§Ø‡§π ‡§∏‡§ø‡§ñ‡§æ‡§§‡•Ä ‡§π‡•à ‡§ï‡§ø ‡§Æ‡•á‡§π‡§®‡§§ ‡§î‡§∞ ‡§ú‡•ç‡§û‡§æ‡§® ‡§ï‡§æ ‡§∏‡§π‡•Ä ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§π‡§Æ ‡§ï‡§ø‡§∏‡•Ä ‡§≠‡•Ä ‡§ï‡§†‡§ø‡§®‡§æ‡§à ‡§ï‡•ã ‡§™‡§æ‡§∞ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§\n",
            "\n",
            "\n",
            "Prompt: Bitte erz√§hle mir eine Geschichte auf Deutsch.\n",
            "Response: Es war einmal in einem kleinen Dorf am Fu√üe eines majest√§tischen Berges, wo die Menschen in Harmonie mit der Natur lebten. In diesem Dorf lebte ein junger Mann namens Lukas, der von Abenteuern tr√§umte und die Welt au√üerhalb seines Heimatdorfes erkunden wollte.\n",
            "\n",
            "Eines Tages h√∂rte Lukas von einem geheimnisvollen Wald, der tief im Gebirge verborgen lag. Man sagte, dass dieser Wald voller magischer Kreaturen und unerforschter Geheimnisse sei. Entschlossen, das Abenteuer seines Lebens zu erleben, packte er einige Vorr√§te und machte sich auf den Weg.\n",
            "\n",
            "Nach mehreren Tagen des Wanderns erreichte Lukas den Rand des geheimnisvollen Waldes. Die B√§ume waren hoch und dicht, und ein sanfter Nebel schwebte √ºber dem Boden. Als er tiefer in den Wald eindrang, bemerkte er, dass die Luft anders roch ‚Äì s√º√ülich und frisch. Pl√∂tzlich h√∂rte er ein leises Fl√ºstern, das ihn an einen kleinen klaren Teich f√ºhrte.\n",
            "\n",
            "Am Ufer des Teiches sa√ü eine wundersch√∂ne Elfe mit schimmernden Fl√ºgeln. Sie stellte sich als Lira vor und erkl√§rte, dass sie die H√ºterin des Waldes sei. Lira erz√§hlte Lukas von den vielen Wundern des Waldes, aber auch von den Gefahren, die ihn bedrohten. Ein dunkler Schatten hatte sich √ºber den Wald gelegt, und nur ein mutiger Mensch konnte helfen, das Gleichgewicht wiederherzustellen.\n",
            "\n",
            "Lukas, voller Entschlossenheit, bot seine Hilfe an. Gemeinsam mit Lira begab er sich auf eine Reise durch den Wald, um die Quelle des √úbels zu finden. Sie begegneten fantastischen Kreaturen, l√∂sten R√§tsel und √ºberwanden zahlreiche Hindernisse. Schlie√ülich entdeckten sie, dass ein alter Zauberer, der einst aus dem Wald verbannt worden war, zur√ºckgekehrt war, um Rache zu nehmen.\n",
            "\n",
            "Mit Mut und List gelang es Lukas und Lira, den Zauberer zu besiegen und den Wald zu befreien. Die Farben des Waldes wurden lebendiger, und die magischen Kreaturen feierten ihre R√ºckkehr zur Freiheit. Als Dank f√ºr seinen Mut erhielt Lukas von Lira ein kleines Amulett, das ihm Gl√ºck bringen sollte.\n",
            "\n",
            "Nach seinem Abenteuer kehrte Lukas in sein Dorf zur√ºck, bereichert durch die Erfahrungen und Freundschaften, die er im geheimnisvollen Wald gemacht hatte. Von diesem Tag an erz√§hlte er den Dorfbewohnern von seinen Erlebnissen und inspirierte sie, ihre eigenen Tr√§ume zu verfolgen und die Wunder der Welt zu entdecken. Und so lebte er gl√ºcklich und zufrieden, immer bereit f√ºr das n√§chste Abenteuer.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from llama_index.llms.openai_like import OpenAILike\n",
        "\n",
        "# Initialize Sutra LLM with necessary parameters\n",
        "llm = OpenAILike(\n",
        "    model=\"sutra-v2\",                    # Sutra model name\n",
        "    api_base=\"https://api.two.ai/v2\",    # Sutra API base URL\n",
        "    api_key=os.getenv(\"SUTRA_API_KEY\"),  # Sutra API key\n",
        "    is_chat_model=True,                  # Mandatory: Set to True for chat-based models\n",
        ")\n",
        "\n",
        "# Multilingual prompts\n",
        "prompts = [\n",
        "    \"‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å‡∞≤‡±ã ‡∞í‡∞ï ‡∞ï‡∞• ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡±Å?\",                         # Telugu\n",
        "    \"Une histoire en fran√ßais, s'il vous pla√Æt.\",     # French\n",
        "    \"Por favor, cu√©ntame una historia en espa√±ol.\",   # Spanish\n",
        "    \"‡§ï‡•É‡§™‡§Ø‡§æ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§ï‡§π‡§æ‡§®‡•Ä ‡§∏‡•Å‡§®‡§æ‡§á‡§è‡•§\",                    # Hindi\n",
        "    \"Bitte erz√§hle mir eine Geschichte auf Deutsch.\"  # German\n",
        "]\n",
        "\n",
        "# Loop through each prompt and print the response\n",
        "for prompt in prompts:\n",
        "    response = llm.complete(prompt)\n",
        "    print(f\"\\nPrompt: {prompt}\")\n",
        "    print(f\"Response: {str(response)}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXzhTgxIbJwI"
      },
      "source": [
        "###Building a Simple Chatbot with LlamaIndex ü¶ô"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmMDK4rRSqI7",
        "outputId": "8f653dd4-5042-421d-f3c5-df00db026820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot: Hello! Type 'exit' to end the conversation.\n",
            "\n",
            "You: hi\n",
            "Chatbot: Hello! How can I assist you today?\n",
            "You: exit\n",
            "Chatbot: Goodbye! üëã\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from llama_index.llms.openai_like import OpenAILike\n",
        "from llama_index.core.llms import ChatMessage\n",
        "\n",
        "\n",
        "# Initialize the Sutra model via LlamaIndex\n",
        "llm = OpenAILike(\n",
        "    model=\"sutra-v2\",                    # Sutra model name\n",
        "    api_base=\"https://api.two.ai/v2\",    # Sutra API base URL\n",
        "    api_key=os.getenv(\"SUTRA_API_KEY\"),  # Sutra API key\n",
        "    is_chat_model=True,                  # Mandatory for chat-based models\n",
        ")\n",
        "\n",
        "# Start the chatbot conversation loop\n",
        "print(\"Chatbot: Hello! Type 'exit' to end the conversation.\\n\")\n",
        "\n",
        "chat_history = []\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")  # Get user input\n",
        "\n",
        "    if user_input.lower() == \"exit\":\n",
        "        print(\"Chatbot: Goodbye! üëã\")\n",
        "        break\n",
        "\n",
        "    # Add user message to chat history\n",
        "    chat_history.append(ChatMessage(role=\"user\", content=user_input))\n",
        "\n",
        "    # Get response from Sutra via LlamaIndex\n",
        "    response = llm.chat(chat_history)\n",
        "\n",
        "    # Print response content\n",
        "    print(\"Chatbot:\", response.message.content)\n",
        "\n",
        "    # Add AI response to chat history\n",
        "    chat_history.append(response.message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnyFjI4ibQ13"
      },
      "source": [
        "###LlamaIndex ü¶ô with the Sutra model for Document Querying"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ry5PamjDTj0S",
        "outputId": "700007ff-8a0f-4687-a876-9ce9097de8fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‡§â‡§§‡•ç‡§§‡§∞: SUTRA 50+ ‡§∏‡•á ‡§Ö‡§ß‡§ø‡§ï ‡§≠‡§æ‡§∑‡§æ‡§ì‡§Ç ‡§ï‡§æ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import faiss\n",
        "from llama_index.core import Document, StorageContext, VectorStoreIndex\n",
        "from llama_index.vector_stores.faiss import FaissVectorStore\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.llms.openai_like import OpenAILike\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "\n",
        "# Set up FAISS index manually\n",
        "dimension = 3072  # For \"text-embedding-3-large\" from OpenAI\n",
        "faiss_index = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "# 1. Hindi text\n",
        "text = \"\"\"\n",
        "SUTRA ‡§¶‡•ã ‡§™‡•ç‡§≤‡•á‡§ü‡§´‡§º‡•â‡§∞‡•ç‡§Æ‡•ç‡§∏ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‡§è‡§ï ‡§¨‡§π‡•Å‡§≠‡§æ‡§∑‡•Ä ‡§¨‡§°‡§º‡•á ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•â‡§°‡§≤ (LMLM) ‡§™‡§∞‡§ø‡§µ‡§æ‡§∞ ‡§π‡•à‡•§\n",
        "SUTRA ‡§ï‡•Ä ‡§°‡•Å‡§Ö‡§≤-‡§ü‡•ç‡§∞‡§æ‡§Ç‡§∏‡§´‡•â‡§∞‡•ç‡§Æ‡§∞ ‡§™‡§¶‡•ç‡§ß‡§§‡§ø MoE ‡§î‡§∞ Dense AI ‡§Æ‡•â‡§°‡§≤ ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞ ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§ï‡•Ä ‡§∂‡§ï‡•ç‡§§‡§ø ‡§ï‡•ã ‡§¨‡§¢‡§º‡§æ‡§§‡•Ä ‡§π‡•à,\n",
        "‡§ú‡•ã 50+ ‡§∏‡•á ‡§Ö‡§ß‡§ø‡§ï ‡§≠‡§æ‡§∑‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§≤‡§æ‡§ó‡§§-‡§ï‡•Å‡§∂‡§≤ ‡§¨‡§π‡•Å‡§≠‡§æ‡§∑‡•Ä ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ‡§è‡§Ç ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à‡•§ ‡§Ø‡§π ‡§∏‡§Ç‡§µ‡§æ‡§¶, ‡§ñ‡•ã‡§ú,\n",
        "‡§î‡§∞ ‡§â‡§®‡•ç‡§®‡§§ ‡§§‡§∞‡•ç‡§ï ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡•ç‡§ï‡•á‡§≤‡•á‡§¨‡§≤ ‡§è‡§Ü‡§à ‡§è‡§™‡•ç‡§≤‡§ø‡§ï‡•á‡§∂‡§® ‡§ï‡•ã ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§¨‡§®‡§æ‡§§‡§æ ‡§π‡•à, ‡§ú‡•ã ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§≠‡§æ‡§∑‡§æ‡§ì‡§Ç, ‡§°‡•ã‡§Æ‡•á‡§® ‡§î‡§∞ ‡§â‡§™‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§â‡§ö‡•ç‡§ö ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§\n",
        "\"\"\"\n",
        "documents = [Document(text=text)]\n",
        "\n",
        "# 2. Embedding model\n",
        "embedding_model = OpenAIEmbedding(\n",
        "    model=\"text-embedding-3-large\",\n",
        "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
        ")\n",
        "\n",
        "# 3. FAISS vector store and storage context\n",
        "vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "# 4. Create the vector index with the given storage context\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents,\n",
        "    embed_model=embedding_model,\n",
        "    storage_context=storage_context,\n",
        ")\n",
        "\n",
        "# 5. Set up Sutra LLM\n",
        "sutra_llm = OpenAILike(\n",
        "    model=\"sutra-v2\",\n",
        "    api_base=\"https://api.two.ai/v2\",\n",
        "    api_key=os.getenv(\"SUTRA_API_KEY\"),\n",
        "    is_chat_model=True,\n",
        ")\n",
        "\n",
        "# 6. Query the index using the Sutra LLM\n",
        "query_engine = index.as_query_engine(llm=sutra_llm)\n",
        "response = query_engine.query(\"SUTRA ‡§ï‡§ø‡§§‡§®‡•Ä ‡§≠‡§æ‡§∑‡§æ‡§ì‡§Ç ‡§ï‡§æ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à?\")\n",
        "\n",
        "# 7. Show the result\n",
        "print(\"‡§â‡§§‡•ç‡§§‡§∞:\", response.response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iofZR6jY6yYx"
      },
      "source": [
        "###Multilingual Chat with Sutra LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "7d79dd7001b14e8783c8086814678257",
            "894662451ef34162b19574cfd3414d13",
            "f906f1e71e7f41f0bc432ac15a0ace33",
            "5098bbe269e14d6eaeb8f99d59896468",
            "b3ffd4aa83464566aaa1e98fe955b019",
            "a2e7457ded384d6c8f46a885177d6592",
            "8a25218a0ab74b8a83fb3b33080d23f5",
            "18b219bd67b7440c97a047dfa8ce4cff",
            "61da7080eb5e462783ebebfe8d322655",
            "075b193a7c084a439d9805313ab0463b",
            "07464a08eee24aac858fd33cb462f1be",
            "4f54acfa998b49bcba7fb16b02057d2f",
            "e2d826261cc945c5861d295f9475266e",
            "365d24c1b443410e952e98c0098cec44"
          ]
        },
        "id": "72uDJ_GN5lYo",
        "outputId": "43288fc9-259b-479b-f388-1edaed80d1d1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d79dd7001b14e8783c8086814678257",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dropdown(description='Select Language:', layout=Layout(height='30px', width='75%'), options=('English', 'Hindi‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5098bbe269e14d6eaeb8f99d59896468",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Textarea(value='', description='Chat History:', disabled=True, layout=Layout(height='400px', width='80%'), pla‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a25218a0ab74b8a83fb3b33080d23f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Text(value='', description='You:', layout=Layout(width='70%'), placeholder='Type your message...', style=TextS‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "075b193a7c084a439d9805313ab0463b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Button(button_style='info', description='Send', layout=Layout(width='20%'), style=ButtonStyle())"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2d826261cc945c5861d295f9475266e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Step 1: Import dependencies\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from llama_index.llms.openai_like import OpenAILike\n",
        "from llama_index.core.chat_engine import SimpleChatEngine\n",
        "\n",
        "# Step 2: Set up Sutra LLM\n",
        "sutra_llm = OpenAILike(\n",
        "    api_base=\"https://api.two.ai/v2\",\n",
        "    api_key=os.getenv(\"SUTRA_API_KEY\"),\n",
        "    model=\"sutra-v2\",\n",
        "    is_chat_model=True,\n",
        ")\n",
        "\n",
        "chat_engine = SimpleChatEngine.from_defaults(llm=sutra_llm)\n",
        "\n",
        "# Step 3: Language options\n",
        "languages = [\n",
        "    \"English\", \"Hindi\", \"Gujarati\", \"Bengali\", \"Tamil\", \"Telugu\", \"Kannada\", \"Malayalam\",\n",
        "    \"Punjabi\", \"Marathi\", \"Urdu\", \"Assamese\", \"Odia\", \"Sanskrit\", \"Korean\", \"Japanese\",\n",
        "    \"Arabic\", \"French\", \"German\", \"Spanish\", \"Portuguese\", \"Russian\", \"Chinese\", \"Vietnamese\",\n",
        "    \"Thai\", \"Indonesian\", \"Turkish\", \"Polish\", \"Ukrainian\", \"Dutch\", \"Italian\", \"Greek\",\n",
        "    \"Hebrew\", \"Persian\"\n",
        "]\n",
        "\n",
        "# Step 4: Create widgets with style\n",
        "lang_dropdown = widgets.Dropdown(\n",
        "    options=languages,\n",
        "    value=\"English\",\n",
        "    description='Select Language:',\n",
        "    style={'description_width': 'initial'},\n",
        "    layout=widgets.Layout(width='75%', height='30px')\n",
        ")\n",
        "\n",
        "chat_log = widgets.Textarea(\n",
        "    value=\"\",\n",
        "    placeholder='Chat history will appear here...',\n",
        "    description='Chat History:',\n",
        "    disabled=True,\n",
        "    layout=widgets.Layout(width='80%', height='400px'),\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "user_input = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Type your message...',\n",
        "    description='You:',\n",
        "    layout=widgets.Layout(width='70%'),\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "send_button = widgets.Button(\n",
        "    description=\"Send\",\n",
        "    button_style='info',\n",
        "    layout=widgets.Layout(width='20%')\n",
        ")\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "# Step 5: Initialize message storage\n",
        "messages = []\n",
        "\n",
        "# Step 6: Send message handler\n",
        "def on_send_click(b):\n",
        "    user_text = user_input.value.strip()\n",
        "    if not user_text:\n",
        "        return\n",
        "    language = lang_dropdown.value\n",
        "\n",
        "    # Add user message to the history\n",
        "    messages.append(f\"User: {user_text}\")\n",
        "    chat_log.value = '\\n'.join(messages)\n",
        "\n",
        "    # Create prompt for Sutra LLM\n",
        "    full_prompt = f\"Please respond only in {language}. User: {user_text}\\nAssistant:\"\n",
        "\n",
        "    # Get response from Sutra LLM\n",
        "    response = chat_engine.chat(full_prompt)\n",
        "    assistant_reply = response.response.strip()\n",
        "\n",
        "    # Add assistant response to chat history\n",
        "    messages.append(f\"Assistant ({language}): {assistant_reply}\")\n",
        "    chat_log.value = '\\n'.join(messages)\n",
        "\n",
        "    # Clear user input field\n",
        "    user_input.value = \"\"\n",
        "\n",
        "# Step 7: Bind button click event\n",
        "send_button.on_click(on_send_click)\n",
        "\n",
        "# Step 8: Display all widgets\n",
        "display(lang_dropdown, chat_log, user_input, send_button, output)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
