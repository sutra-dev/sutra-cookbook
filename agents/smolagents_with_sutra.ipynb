{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZjzwKNkuaSW"
      },
      "source": [
        "<div style=\"display: flex; align-items: center; gap: 40px;\">\n",
        "\n",
        "<img src=\"https://framerusercontent.com/images/9vH8BcjXKRcC5OrSfkohhSyDgX0.png\" width=\"130\">\n",
        "<img src=\"https://debuggercafe.com/wp-content/uploads/2025/01/smolagents-logo.png\" width=\"140\">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<div>\n",
        "  <h2>SUTRA by TWO Platforms</h2>\n",
        "  <p>SUTRA is a family of large multi-lingual language (LMLMs) models pioneered by Two Platforms. SUTRAâ€™s dual-transformer approach extends the power of both MoE and Dense AI language model architectures, delivering cost-efficient multilingual capabilities for over 50+ languages. It powers scalable AI applications for conversation, search, and advanced reasoning, ensuring high-performance across diverse languages, domains and applications.</p>\n",
        "\n",
        "  <h2>Smolagents With SUTRA</h2>\n",
        "  <p>Smolagents is an AI agent framework recently launched by the Hugging Face team to simplify the process of developing AI agents.\n",
        "\n",
        "Itâ€™s a lightweight library that prioritizes practicality. This means it can build AI agents in a few lines of code but focuses more on simple implementation than creating the whole agent system in production.</p>\n",
        "</div>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1trbomQyteYsEjuH-ejyTtZqqk2JQtXzA?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAlmORCywBAl"
      },
      "source": [
        "## Get Your API Keys\n",
        "\n",
        "Before you begin, make sure you have:\n",
        "\n",
        "1. A SUTRA API key (Get yours at [TWO AI's SUTRA API page](https://www.two.ai/sutra/api))\n",
        "2. Basic familiarity with Python and Jupyter notebooks\n",
        "\n",
        "This notebook is designed to run in Google Colab, so no local Python installation is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fooO7HybwNZz"
      },
      "source": [
        "###ðŸ”§ 1. Install Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ALsRvMBGmCiV"
      },
      "outputs": [],
      "source": [
        "!pip install duckduckgo-search pyttsx3 gTTS langchain_community langchain_chroma langchain_huggingface \"smolagents[litellm]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYGgPC9QwRNs"
      },
      "source": [
        "###ðŸ”‘ 2. Set Environment Variables (API Keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aP5S-0rHnWWV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set the API key from Colab secrets\n",
        "os.environ[\"SUTRA_API_KEY\"] = userdata.get(\"SUTRA_API_KEY\")\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get(\"HF_TOKEN\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIAuIgmCwris"
      },
      "source": [
        "###Initialize Sutra LLM via LiteLLMModel (SmolAgents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du3gNOSzmOo-",
        "outputId": "ea2446eb-a20f-4773-bf36-bb82ed329a1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatMessage(role='assistant', content='à¤®à¤‚à¤—à¤² à¤—à¥à¤°à¤¹, à¤œà¤¿à¤¸à¥‡ à¤…à¤‚à¤—à¥à¤°à¥‡à¤œà¥€ à¤®à¥‡à¤‚ Mars à¤•à¤¹à¤¾ à¤œà¤¾à¤¤à¤¾ à¤¹à¥ˆ, à¤¸à¥Œà¤° à¤®à¤‚à¤¡à¤² à¤•à¤¾ à¤šà¥Œà¤¥à¤¾ à¤—à¥à¤°à¤¹ à¤¹à¥ˆ à¤”à¤° à¤‡à¤¸à¥‡ à¤²à¤¾à¤² à¤—à¥à¤°à¤¹ à¤•à¥‡ à¤°à¥‚à¤ª à¤®à¥‡à¤‚ à¤­à¥€ à¤œà¤¾à¤¨à¤¾ à¤œà¤¾à¤¤à¤¾ à¤¹à¥ˆà¥¤ à¤‡à¤¸à¤•à¤¾ à¤¨à¤¾à¤® à¤°à¥‹à¤®à¤¨ à¤¯à¥à¤¦à¥à¤§ à¤•à¥‡ à¤¦à¥‡à¤µà¤¤à¤¾ à¤•à¥‡ à¤¨à¤¾à¤® à¤ªà¤° à¤°à¤–à¤¾ à¤—à¤¯à¤¾ à¤¹à¥ˆà¥¤ à¤®à¤‚à¤—à¤² à¤•à¤¾ à¤°à¤‚à¤— à¤²à¤¾à¤² à¤¹à¥ˆ, à¤œà¥‹ à¤•à¤¿ à¤‡à¤¸à¤•à¥‡ à¤¸à¤¤à¤¹ à¤ªà¤° à¤®à¥Œà¤œà¥‚à¤¦ à¤†à¤¯à¤°à¤¨ à¤‘à¤•à¥à¤¸à¤¾à¤‡à¤¡ (à¤œà¤‚à¤—) à¤•à¥‡ à¤•à¤¾à¤°à¤£ à¤¹à¥‹à¤¤à¤¾ à¤¹à¥ˆà¥¤ à¤®à¤‚à¤—à¤² à¤•à¤¾ à¤µà¥à¤¯à¤¾à¤¸ à¤²à¤—à¤­à¤— 6,779 à¤•à¤¿à¤²à¥‹à¤®à¥€à¤Ÿà¤° à¤¹à¥ˆ, à¤œà¥‹ à¤ªà¥ƒà¤¥à¥à¤µà¥€ à¤•à¥‡ à¤†à¤§à¥‡ à¤¸à¥‡ à¤¥à¥‹à¤¡à¤¼à¤¾ à¤…à¤§à¤¿à¤• à¤¹à¥ˆà¥¤ à¤¯à¤¹ à¤—à¥à¤°à¤¹ à¤¸à¥‚à¤°à¥à¤¯ à¤¸à¥‡ à¤¤à¥€à¤¸à¤°à¥€ à¤¦à¥‚à¤°à¥€ à¤ªà¤° à¤¸à¥à¤¥à¤¿à¤¤ à¤¹à¥ˆ à¤”à¤° à¤‡à¤¸à¤•à¥€ à¤•à¤•à¥à¤·à¤¾ à¤•à¥‹ à¤ªà¥‚à¤°à¤¾ à¤•à¤°à¤¨à¥‡ à¤®à¥‡à¤‚ à¤²à¤—à¤­à¤— 687 à¤¦à¤¿à¤¨ à¤²à¤—à¤¤à¥‡ à¤¹à¥ˆà¤‚à¥¤\\n\\nà¤®à¤‚à¤—à¤² à¤—à¥à¤°à¤¹ à¤•à¥€ à¤¸à¤¤à¤¹ à¤ªà¤° à¤•à¤ˆ à¤µà¤¿à¤¶à¥‡à¤·à¤¤à¤¾à¤à¤ à¤¹à¥ˆà¤‚, à¤œà¥ˆà¤¸à¥‡ à¤•à¤¿ à¤—à¤¹à¤°à¥€ à¤˜à¤¾à¤Ÿà¤¿à¤¯à¤¾à¤, à¤µà¤¿à¤¶à¤¾à¤² à¤œà¥à¤µà¤¾à¤²à¤¾à¤®à¥à¤–à¥€ à¤”à¤° à¤µà¤¿à¤¸à¥à¤¤à¥ƒà¤¤ à¤®à¥ˆà¤¦à¤¾à¤¨à¥€ à¤‡à¤²à¤¾à¤•à¤¼à¥‡à¥¤ à¤‡à¤¸à¤•à¥€ à¤¸à¤¬à¤¸à¥‡ à¤¬à¤¡à¤¼à¥€ à¤µà¤¿à¤¶à¥‡à¤·à¤¤à¤¾ à¤“à¤²à¤‚à¤ªà¤¸ à¤®à¥‰à¤¨à¥à¤¸ à¤¹à¥ˆ, à¤œà¥‹ à¤¸à¥Œà¤° à¤®à¤‚à¤¡à¤² à¤•à¤¾ à¤¸à¤¬à¤¸à¥‡ à¤¬à¤¡à¤¼à¤¾ à¤œà¥à¤µà¤¾à¤²à¤¾à¤®à¥à¤–à¥€ à¤¹à¥ˆ à¤”à¤° à¤‡à¤¸à¤•à¥€ à¤Šà¤à¤šà¤¾à¤ˆ à¤²à¤—à¤­à¤— 22 à¤•à¤¿à¤²à¥‹à¤®à¥€à¤Ÿà¤° à¤¹à¥ˆà¥¤ à¤‡à¤¸à¤•à¥‡ à¤…à¤²à¤¾à¤µà¤¾, à¤µà¥‡à¤²à¤¿à¤¸ à¤®à¤¾à¤°à¤¿à¤¨à¥‡à¤°à¤¿à¤¸, à¤œà¥‹ à¤à¤• à¤µà¤¿à¤¶à¤¾à¤² à¤˜à¤¾à¤Ÿà¥€ à¤¹à¥ˆ, à¤²à¤—à¤­à¤— 4,000 à¤•à¤¿à¤²à¥‹à¤®à¥€à¤Ÿà¤° à¤²à¤‚à¤¬à¥€ à¤¹à¥ˆ à¤”à¤° à¤¯à¤¹ à¤§à¤°à¤¤à¥€ à¤•à¥€ à¤—à¥à¤°à¥ˆà¤‚à¤¡ à¤•à¥ˆà¤¨à¥à¤¯à¤¨ à¤¸à¥‡ à¤­à¥€ à¤¬à¤¡à¤¼à¥€ à¤¹à¥ˆà¥¤ à¤‡à¤¨ à¤­à¥Œà¤—à¥‹à¤²à¤¿à¤• à¤µà¤¿à¤¶à¥‡à¤·à¤¤à¤¾à¤“à¤‚ à¤¨à¥‡ à¤®à¤‚à¤—à¤² à¤—à¥à¤°à¤¹ à¤•à¥‹ à¤µà¥ˆà¤œà¥à¤žà¤¾à¤¨à¤¿à¤• à¤…à¤¨à¥à¤¸à¤‚à¤§à¤¾à¤¨ à¤•à¤¾ à¤à¤• à¤ªà¥à¤°à¤®à¥à¤– à¤µà¤¿à¤·à¤¯ à¤¬à¤¨à¤¾ à¤¦à¤¿à¤¯à¤¾ à¤¹à¥ˆà¥¤\\n\\nà¤®à¤‚à¤—à¤² à¤•à¥‡ à¤µà¤¾à¤¯à¥à¤®à¤‚à¤¡à¤² à¤•à¥€ à¤¸à¤‚à¤°à¤šà¤¨à¤¾ à¤ªà¥ƒà¤¥à¥à¤µà¥€ à¤•à¥€ à¤¤à¥à¤²à¤¨à¤¾ à¤®à¥‡à¤‚ à¤¬à¤¹à¥à¤¤ à¤ªà¤¤à¤²à¥€ à¤¹à¥ˆ, à¤œà¤¿à¤¸à¤®à¥‡à¤‚ à¤®à¥à¤–à¥à¤¯à¤¤à¤ƒ à¤•à¤¾à¤°à¥à¤¬à¤¨ à¤¡à¤¾à¤‡à¤‘à¤•à¥à¤¸à¤¾à¤‡à¤¡ (95.3%), à¤¨à¤¾à¤‡à¤Ÿà¥à¤°à¥‹à¤œà¤¨ (2.7%) à¤”à¤° à¤†à¤°à¥à¤—à¤¨ (1.6%) à¤¶à¤¾à¤®à¤¿à¤² à¤¹à¥ˆà¤‚à¥¤ à¤µà¤¾à¤¯à¥à¤®à¤‚à¤¡à¤² à¤•à¥€ à¤‡à¤¸ à¤¸à¤‚à¤°à¤šà¤¨à¤¾ à¤•à¥‡ à¤•à¤¾à¤°à¤£ à¤®à¤‚à¤—à¤² à¤ªà¤° à¤¤à¤¾à¤ªà¤®à¤¾à¤¨ à¤¬à¤¹à¥à¤¤ à¤•à¤® à¤°à¤¹à¤¤à¤¾ à¤¹à¥ˆ, à¤”à¤¸à¤¤à¤¨ -80 à¤¡à¤¿à¤—à¥à¤°à¥€ à¤«à¤¾à¤°à¥‡à¤¨à¤¹à¤¾à¤‡à¤Ÿ (-62 à¤¡à¤¿à¤—à¥à¤°à¥€ à¤¸à¥‡à¤²à¥à¤¸à¤¿à¤¯à¤¸) à¤¤à¤• à¤—à¤¿à¤° à¤¸à¤•à¤¤à¤¾ à¤¹à¥ˆà¥¤ à¤‡à¤¸à¤•à¥‡ à¤…à¤²à¤¾à¤µà¤¾, à¤®à¤‚à¤—à¤² à¤ªà¤° à¤§à¥‚à¤² à¤­à¤°à¥€ à¤†à¤à¤§à¤¿à¤¯à¤¾à¤ à¤…à¤•à¥à¤¸à¤° à¤¹à¥‹à¤¤à¥€ à¤¹à¥ˆà¤‚, à¤œà¥‹ à¤—à¥à¤°à¤¹ à¤•à¥‡ à¤ªà¥‚à¤°à¥‡ à¤•à¥à¤·à¥‡à¤¤à¥à¤° à¤•à¥‹ à¤¢à¤• à¤¸à¤•à¤¤à¥€ à¤¹à¥ˆà¤‚à¥¤\\n\\nà¤ªà¤¿à¤›à¤²à¥‡ à¤•à¥à¤› à¤µà¤°à¥à¤·à¥‹à¤‚ à¤®à¥‡à¤‚, à¤®à¤‚à¤—à¤² à¤ªà¤° à¤œà¥€à¤µà¤¨ à¤•à¥€ à¤¸à¤‚à¤­à¤¾à¤µà¤¨à¤¾à¤“à¤‚ à¤•à¥€ à¤–à¥‹à¤œ à¤•à¥‡ à¤²à¤¿à¤ à¤•à¤ˆ à¤®à¤¿à¤¶à¤¨ à¤­à¥‡à¤œà¥‡ à¤—à¤ à¤¹à¥ˆà¤‚à¥¤ NASA à¤•à¥‡ à¤°à¥‹à¤µà¤° à¤œà¥ˆà¤¸à¥‡ à¤•à¥à¤¯à¥‚à¤°à¤¿à¤¯à¥‹à¤¸à¤¿à¤Ÿà¥€ à¤”à¤° à¤ªà¤°à¥à¤¸à¥‡à¤µà¥‡à¤°à¥‡à¤‚à¤¸ à¤¨à¥‡ à¤®à¤‚à¤—à¤² à¤•à¥€ à¤¸à¤¤à¤¹ à¤ªà¤° à¤ªà¤¾à¤¨à¥€ à¤•à¥‡ à¤¸à¤‚à¤•à¥‡à¤¤ à¤”à¤° à¤œà¥ˆà¤µà¤¿à¤• à¤¸à¤¾à¤®à¤—à¥à¤°à¥€ à¤•à¥€ à¤–à¥‹à¤œ à¤•à¥€ à¤¹à¥ˆ, à¤œà¤¿à¤¸à¤¸à¥‡ à¤¯à¤¹ à¤†à¤¶à¤‚à¤•à¤¾ à¤œà¤¤à¤¾à¤ˆ à¤œà¤¾ à¤°à¤¹à¥€ à¤¹à¥ˆ à¤•à¤¿ à¤¯à¤¹à¤¾à¤ à¤•à¤­à¥€ à¤¸à¥‚à¤•à¥à¤·à¥à¤®à¤œà¥€à¤µ à¤¹à¥‹ à¤¸à¤•à¤¤à¥‡ à¤¥à¥‡à¥¤ à¤µà¥ˆà¤œà¥à¤žà¤¾à¤¨à¤¿à¤•à¥‹à¤‚ à¤•à¤¾ à¤®à¤¾à¤¨à¤¨à¤¾ à¤¹à¥ˆ à¤•à¤¿ à¤¯à¤¦à¤¿ à¤®à¤‚à¤—à¤² à¤ªà¤°', tool_calls=None, raw=ModelResponse(id='5Rv89htHUXCZyawSsCMo24', created=1748849985, model='sutra-v2', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='à¤®à¤‚à¤—à¤² à¤—à¥à¤°à¤¹, à¤œà¤¿à¤¸à¥‡ à¤…à¤‚à¤—à¥à¤°à¥‡à¤œà¥€ à¤®à¥‡à¤‚ Mars à¤•à¤¹à¤¾ à¤œà¤¾à¤¤à¤¾ à¤¹à¥ˆ, à¤¸à¥Œà¤° à¤®à¤‚à¤¡à¤² à¤•à¤¾ à¤šà¥Œà¤¥à¤¾ à¤—à¥à¤°à¤¹ à¤¹à¥ˆ à¤”à¤° à¤‡à¤¸à¥‡ à¤²à¤¾à¤² à¤—à¥à¤°à¤¹ à¤•à¥‡ à¤°à¥‚à¤ª à¤®à¥‡à¤‚ à¤­à¥€ à¤œà¤¾à¤¨à¤¾ à¤œà¤¾à¤¤à¤¾ à¤¹à¥ˆà¥¤ à¤‡à¤¸à¤•à¤¾ à¤¨à¤¾à¤® à¤°à¥‹à¤®à¤¨ à¤¯à¥à¤¦à¥à¤§ à¤•à¥‡ à¤¦à¥‡à¤µà¤¤à¤¾ à¤•à¥‡ à¤¨à¤¾à¤® à¤ªà¤° à¤°à¤–à¤¾ à¤—à¤¯à¤¾ à¤¹à¥ˆà¥¤ à¤®à¤‚à¤—à¤² à¤•à¤¾ à¤°à¤‚à¤— à¤²à¤¾à¤² à¤¹à¥ˆ, à¤œà¥‹ à¤•à¤¿ à¤‡à¤¸à¤•à¥‡ à¤¸à¤¤à¤¹ à¤ªà¤° à¤®à¥Œà¤œà¥‚à¤¦ à¤†à¤¯à¤°à¤¨ à¤‘à¤•à¥à¤¸à¤¾à¤‡à¤¡ (à¤œà¤‚à¤—) à¤•à¥‡ à¤•à¤¾à¤°à¤£ à¤¹à¥‹à¤¤à¤¾ à¤¹à¥ˆà¥¤ à¤®à¤‚à¤—à¤² à¤•à¤¾ à¤µà¥à¤¯à¤¾à¤¸ à¤²à¤—à¤­à¤— 6,779 à¤•à¤¿à¤²à¥‹à¤®à¥€à¤Ÿà¤° à¤¹à¥ˆ, à¤œà¥‹ à¤ªà¥ƒà¤¥à¥à¤µà¥€ à¤•à¥‡ à¤†à¤§à¥‡ à¤¸à¥‡ à¤¥à¥‹à¤¡à¤¼à¤¾ à¤…à¤§à¤¿à¤• à¤¹à¥ˆà¥¤ à¤¯à¤¹ à¤—à¥à¤°à¤¹ à¤¸à¥‚à¤°à¥à¤¯ à¤¸à¥‡ à¤¤à¥€à¤¸à¤°à¥€ à¤¦à¥‚à¤°à¥€ à¤ªà¤° à¤¸à¥à¤¥à¤¿à¤¤ à¤¹à¥ˆ à¤”à¤° à¤‡à¤¸à¤•à¥€ à¤•à¤•à¥à¤·à¤¾ à¤•à¥‹ à¤ªà¥‚à¤°à¤¾ à¤•à¤°à¤¨à¥‡ à¤®à¥‡à¤‚ à¤²à¤—à¤­à¤— 687 à¤¦à¤¿à¤¨ à¤²à¤—à¤¤à¥‡ à¤¹à¥ˆà¤‚à¥¤\\n\\nà¤®à¤‚à¤—à¤² à¤—à¥à¤°à¤¹ à¤•à¥€ à¤¸à¤¤à¤¹ à¤ªà¤° à¤•à¤ˆ à¤µà¤¿à¤¶à¥‡à¤·à¤¤à¤¾à¤à¤ à¤¹à¥ˆà¤‚, à¤œà¥ˆà¤¸à¥‡ à¤•à¤¿ à¤—à¤¹à¤°à¥€ à¤˜à¤¾à¤Ÿà¤¿à¤¯à¤¾à¤, à¤µà¤¿à¤¶à¤¾à¤² à¤œà¥à¤µà¤¾à¤²à¤¾à¤®à¥à¤–à¥€ à¤”à¤° à¤µà¤¿à¤¸à¥à¤¤à¥ƒà¤¤ à¤®à¥ˆà¤¦à¤¾à¤¨à¥€ à¤‡à¤²à¤¾à¤•à¤¼à¥‡à¥¤ à¤‡à¤¸à¤•à¥€ à¤¸à¤¬à¤¸à¥‡ à¤¬à¤¡à¤¼à¥€ à¤µà¤¿à¤¶à¥‡à¤·à¤¤à¤¾ à¤“à¤²à¤‚à¤ªà¤¸ à¤®à¥‰à¤¨à¥à¤¸ à¤¹à¥ˆ, à¤œà¥‹ à¤¸à¥Œà¤° à¤®à¤‚à¤¡à¤² à¤•à¤¾ à¤¸à¤¬à¤¸à¥‡ à¤¬à¤¡à¤¼à¤¾ à¤œà¥à¤µà¤¾à¤²à¤¾à¤®à¥à¤–à¥€ à¤¹à¥ˆ à¤”à¤° à¤‡à¤¸à¤•à¥€ à¤Šà¤à¤šà¤¾à¤ˆ à¤²à¤—à¤­à¤— 22 à¤•à¤¿à¤²à¥‹à¤®à¥€à¤Ÿà¤° à¤¹à¥ˆà¥¤ à¤‡à¤¸à¤•à¥‡ à¤…à¤²à¤¾à¤µà¤¾, à¤µà¥‡à¤²à¤¿à¤¸ à¤®à¤¾à¤°à¤¿à¤¨à¥‡à¤°à¤¿à¤¸, à¤œà¥‹ à¤à¤• à¤µà¤¿à¤¶à¤¾à¤² à¤˜à¤¾à¤Ÿà¥€ à¤¹à¥ˆ, à¤²à¤—à¤­à¤— 4,000 à¤•à¤¿à¤²à¥‹à¤®à¥€à¤Ÿà¤° à¤²à¤‚à¤¬à¥€ à¤¹à¥ˆ à¤”à¤° à¤¯à¤¹ à¤§à¤°à¤¤à¥€ à¤•à¥€ à¤—à¥à¤°à¥ˆà¤‚à¤¡ à¤•à¥ˆà¤¨à¥à¤¯à¤¨ à¤¸à¥‡ à¤­à¥€ à¤¬à¤¡à¤¼à¥€ à¤¹à¥ˆà¥¤ à¤‡à¤¨ à¤­à¥Œà¤—à¥‹à¤²à¤¿à¤• à¤µà¤¿à¤¶à¥‡à¤·à¤¤à¤¾à¤“à¤‚ à¤¨à¥‡ à¤®à¤‚à¤—à¤² à¤—à¥à¤°à¤¹ à¤•à¥‹ à¤µà¥ˆà¤œà¥à¤žà¤¾à¤¨à¤¿à¤• à¤…à¤¨à¥à¤¸à¤‚à¤§à¤¾à¤¨ à¤•à¤¾ à¤à¤• à¤ªà¥à¤°à¤®à¥à¤– à¤µà¤¿à¤·à¤¯ à¤¬à¤¨à¤¾ à¤¦à¤¿à¤¯à¤¾ à¤¹à¥ˆà¥¤\\n\\nà¤®à¤‚à¤—à¤² à¤•à¥‡ à¤µà¤¾à¤¯à¥à¤®à¤‚à¤¡à¤² à¤•à¥€ à¤¸à¤‚à¤°à¤šà¤¨à¤¾ à¤ªà¥ƒà¤¥à¥à¤µà¥€ à¤•à¥€ à¤¤à¥à¤²à¤¨à¤¾ à¤®à¥‡à¤‚ à¤¬à¤¹à¥à¤¤ à¤ªà¤¤à¤²à¥€ à¤¹à¥ˆ, à¤œà¤¿à¤¸à¤®à¥‡à¤‚ à¤®à¥à¤–à¥à¤¯à¤¤à¤ƒ à¤•à¤¾à¤°à¥à¤¬à¤¨ à¤¡à¤¾à¤‡à¤‘à¤•à¥à¤¸à¤¾à¤‡à¤¡ (95.3%), à¤¨à¤¾à¤‡à¤Ÿà¥à¤°à¥‹à¤œà¤¨ (2.7%) à¤”à¤° à¤†à¤°à¥à¤—à¤¨ (1.6%) à¤¶à¤¾à¤®à¤¿à¤² à¤¹à¥ˆà¤‚à¥¤ à¤µà¤¾à¤¯à¥à¤®à¤‚à¤¡à¤² à¤•à¥€ à¤‡à¤¸ à¤¸à¤‚à¤°à¤šà¤¨à¤¾ à¤•à¥‡ à¤•à¤¾à¤°à¤£ à¤®à¤‚à¤—à¤² à¤ªà¤° à¤¤à¤¾à¤ªà¤®à¤¾à¤¨ à¤¬à¤¹à¥à¤¤ à¤•à¤® à¤°à¤¹à¤¤à¤¾ à¤¹à¥ˆ, à¤”à¤¸à¤¤à¤¨ -80 à¤¡à¤¿à¤—à¥à¤°à¥€ à¤«à¤¾à¤°à¥‡à¤¨à¤¹à¤¾à¤‡à¤Ÿ (-62 à¤¡à¤¿à¤—à¥à¤°à¥€ à¤¸à¥‡à¤²à¥à¤¸à¤¿à¤¯à¤¸) à¤¤à¤• à¤—à¤¿à¤° à¤¸à¤•à¤¤à¤¾ à¤¹à¥ˆà¥¤ à¤‡à¤¸à¤•à¥‡ à¤…à¤²à¤¾à¤µà¤¾, à¤®à¤‚à¤—à¤² à¤ªà¤° à¤§à¥‚à¤² à¤­à¤°à¥€ à¤†à¤à¤§à¤¿à¤¯à¤¾à¤ à¤…à¤•à¥à¤¸à¤° à¤¹à¥‹à¤¤à¥€ à¤¹à¥ˆà¤‚, à¤œà¥‹ à¤—à¥à¤°à¤¹ à¤•à¥‡ à¤ªà¥‚à¤°à¥‡ à¤•à¥à¤·à¥‡à¤¤à¥à¤° à¤•à¥‹ à¤¢à¤• à¤¸à¤•à¤¤à¥€ à¤¹à¥ˆà¤‚à¥¤\\n\\nà¤ªà¤¿à¤›à¤²à¥‡ à¤•à¥à¤› à¤µà¤°à¥à¤·à¥‹à¤‚ à¤®à¥‡à¤‚, à¤®à¤‚à¤—à¤² à¤ªà¤° à¤œà¥€à¤µà¤¨ à¤•à¥€ à¤¸à¤‚à¤­à¤¾à¤µà¤¨à¤¾à¤“à¤‚ à¤•à¥€ à¤–à¥‹à¤œ à¤•à¥‡ à¤²à¤¿à¤ à¤•à¤ˆ à¤®à¤¿à¤¶à¤¨ à¤­à¥‡à¤œà¥‡ à¤—à¤ à¤¹à¥ˆà¤‚à¥¤ NASA à¤•à¥‡ à¤°à¥‹à¤µà¤° à¤œà¥ˆà¤¸à¥‡ à¤•à¥à¤¯à¥‚à¤°à¤¿à¤¯à¥‹à¤¸à¤¿à¤Ÿà¥€ à¤”à¤° à¤ªà¤°à¥à¤¸à¥‡à¤µà¥‡à¤°à¥‡à¤‚à¤¸ à¤¨à¥‡ à¤®à¤‚à¤—à¤² à¤•à¥€ à¤¸à¤¤à¤¹ à¤ªà¤° à¤ªà¤¾à¤¨à¥€ à¤•à¥‡ à¤¸à¤‚à¤•à¥‡à¤¤ à¤”à¤° à¤œà¥ˆà¤µà¤¿à¤• à¤¸à¤¾à¤®à¤—à¥à¤°à¥€ à¤•à¥€ à¤–à¥‹à¤œ à¤•à¥€ à¤¹à¥ˆ, à¤œà¤¿à¤¸à¤¸à¥‡ à¤¯à¤¹ à¤†à¤¶à¤‚à¤•à¤¾ à¤œà¤¤à¤¾à¤ˆ à¤œà¤¾ à¤°à¤¹à¥€ à¤¹à¥ˆ à¤•à¤¿ à¤¯à¤¹à¤¾à¤ à¤•à¤­à¥€ à¤¸à¥‚à¤•à¥à¤·à¥à¤®à¤œà¥€à¤µ à¤¹à¥‹ à¤¸à¤•à¤¤à¥‡ à¤¥à¥‡à¥¤ à¤µà¥ˆà¤œà¥à¤žà¤¾à¤¨à¤¿à¤•à¥‹à¤‚ à¤•à¤¾ à¤®à¤¾à¤¨à¤¨à¤¾ à¤¹à¥ˆ à¤•à¤¿ à¤¯à¤¦à¤¿ à¤®à¤‚à¤—à¤² à¤ªà¤°', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None), service_tier=None), token_usage=TokenUsage(input_tokens=0, output_tokens=0, total_tokens=0))\n"
          ]
        }
      ],
      "source": [
        "from smolagents import LiteLLMModel\n",
        "\n",
        "# Multilingual message (in Hindi)\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"à¤®à¥à¤à¥‡ à¤®à¤‚à¤—à¤² à¤—à¥à¤°à¤¹ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ 5 à¤ªà¥ˆà¤°à¤¾à¤—à¥à¤°à¤¾à¤« à¤¦à¥€à¤œà¤¿à¤\"}]}\n",
        "]\n",
        "\n",
        "# Instantiate LiteLLMModel with Sutra model\n",
        "model = LiteLLMModel(\n",
        "    model_id=\"openai/sutra-v2\",                  # Use Sutra via LiteLLM\n",
        "    api_base=\"https://api.two.ai/v2\",            # Sutra API base from TwoAI\n",
        "    api_key=os.getenv(\"SUTRA_API_KEY\"),          # Pass API key\n",
        "    temperature=0.7,\n",
        "    max_tokens=500\n",
        ")\n",
        "\n",
        "# Generate response\n",
        "response = model(messages)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP7UJ1ZmxKkz"
      },
      "source": [
        "###Create a CodeAgent with the DuckDuckGo Search Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDG4nMSqmciF"
      },
      "outputs": [],
      "source": [
        "from smolagents import LiteLLMModel, CodeAgent, DuckDuckGoSearchTool\n",
        "\n",
        "# Initialize Sutra model\n",
        "model = LiteLLMModel(\n",
        "    model_id=\"openai/sutra-v2\",\n",
        "    api_base=\"https://api.two.ai/v2\",\n",
        "    api_key=os.getenv(\"SUTRA_API_KEY\"),\n",
        "    temperature=0.7,\n",
        "    max_tokens=500\n",
        ")\n",
        "\n",
        "# Initialize CodeAgent with DuckDuckGo search tool and Sutra model\n",
        "agent = CodeAgent(tools=[DuckDuckGoSearchTool()], model=model)\n",
        "\n",
        "# Run a query using the agent\n",
        "agent.run(\"à°à°¸à±€à°¸à±€ 2025 à°«à±ˆà°¨à°²à± à°Žà°µà°°à± à°—à±†à°²à°¿à°šà°¾à°°à±?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EgyDDp9yvLB"
      },
      "source": [
        "###Text-to-Speech Response from Sutra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqVVPfC3ols7"
      },
      "outputs": [],
      "source": [
        "# âœ… Import necessary modules\n",
        "from smolagents import CodeAgent, LiteLLMModel\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "\n",
        "\n",
        "# âœ… Initialize Sutra Model\n",
        "model = LiteLLMModel(\n",
        "    model_id=\"openai/sutra-v2\",\n",
        "    api_base=\"https://api.two.ai/v2\",\n",
        "    api_key=os.getenv(\"SUTRA_API_KEY\"),\n",
        "    temperature=0.7,\n",
        "    max_tokens=1024\n",
        ")\n",
        "\n",
        "# âœ… Initialize CodeAgent\n",
        "agent = CodeAgent(tools=[], model=model, add_base_tools=True)\n",
        "\n",
        "# âœ… Run the agent\n",
        "response = agent.run(\"About TWO AI\")\n",
        "print(\"Agent Response:\", response)\n",
        "\n",
        "# âœ… Convert response to speech using gTTS\n",
        "tts = gTTS(text=str(response))\n",
        "tts.save(\"response.mp3\")\n",
        "\n",
        "# âœ… Play audio in notebook\n",
        "Audio(\"response.mp3\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS6adKCXy12D"
      },
      "source": [
        "###Using SmolAgents to perform RAG on URLs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vBidBqOq_bm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "from smolagents import LiteLLMModel, Tool\n",
        "from smolagents.agents import CodeAgent\n",
        "\n",
        "\n",
        "# âœ… Step 1: Load text content from a URL\n",
        "def load_text_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    return response.text\n",
        "\n",
        "\n",
        "# âœ… Example: Use your own URL\n",
        "url = \"https://arxiv.org/pdf/1706.03762\"  # Replace with your own\n",
        "page_content = load_text_from_url(url)\n",
        "\n",
        "source_docs = [Document(page_content=page_content, metadata={\"source\": url})]\n",
        "\n",
        "# âœ… Step 2: Split text into chunks\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"thenlper/gte-small\")\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
        "    tokenizer,\n",
        "    chunk_size=200,\n",
        "    chunk_overlap=20,\n",
        "    add_start_index=True,\n",
        "    strip_whitespace=True,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
        ")\n",
        "\n",
        "print(\"Splitting document...\")\n",
        "docs_processed = []\n",
        "unique_texts = {}\n",
        "for doc in tqdm(source_docs):\n",
        "    new_docs = text_splitter.split_documents([doc])\n",
        "    for new_doc in new_docs:\n",
        "        if new_doc.page_content not in unique_texts:\n",
        "            unique_texts[new_doc.page_content] = True\n",
        "            docs_processed.append(new_doc)\n",
        "\n",
        "# âœ… Step 3: Embed & store in vector DB\n",
        "print(\"Embedding documents...\")\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "vector_store = Chroma.from_documents(docs_processed, embeddings, persist_directory=\"./chroma_db\")\n",
        "\n",
        "\n",
        "# âœ… Step 4: Create Retrieval Tool\n",
        "class RetrieverTool(Tool):\n",
        "    name = \"retriever\"\n",
        "    description = \"Retrieve the most relevant docs from URL-based knowledge base.\"\n",
        "    inputs = {\n",
        "        \"query\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The query for semantic search.\",\n",
        "        }\n",
        "    }\n",
        "    output_type = \"string\"\n",
        "\n",
        "    def __init__(self, vector_store, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.vector_store = vector_store\n",
        "\n",
        "    def forward(self, query: str) -> str:\n",
        "        assert isinstance(query, str), \"Query must be a string\"\n",
        "        docs = self.vector_store.similarity_search(query, k=3)\n",
        "        return \"\\nRetrieved documents:\\n\" + \"\".join(\n",
        "            [f\"\\n\\n===== Document {i} =====\\n\" + doc.page_content for i, doc in enumerate(docs)]\n",
        "        )\n",
        "\n",
        "\n",
        "retriever_tool = RetrieverTool(vector_store)\n",
        "\n",
        "# âœ… Step 5: Setup Sutra LLM\n",
        "model = LiteLLMModel(\n",
        "    model_id=\"openai/sutra-v2\",\n",
        "    api_base=\"https://api.two.ai/v2\",\n",
        "    api_key=userdata.get(\"SUTRA_API_KEY\"),\n",
        ")\n",
        "\n",
        "# âœ… Step 6: Run Agent\n",
        "agent = CodeAgent(\n",
        "    tools=[retriever_tool],\n",
        "    model=model,\n",
        "    max_steps=4,\n",
        "    verbosity_level=2,\n",
        ")\n",
        "\n",
        "query = \"What are encoders and decoders\"\n",
        "agent_output = agent.run(query)\n",
        "\n",
        "print(\"Final output:\")\n",
        "print(agent_output)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
